<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://refstop.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://refstop.github.io/" rel="alternate" type="text/html" /><updated>2021-07-05T01:29:13+09:00</updated><id>https://refstop.github.io/feed.xml</id><title type="html">Refstop의 연구일지</title><subtitle>Deep Learning 및 SLAM을 공부하고 있습니다.</subtitle><author><name>Refstop</name></author><entry><title type="html">[Udacity] Deep Learning (7) - CNN 구성과 LeNet-5(작성중)</title><link href="https://refstop.github.io/uda-lenet.html" rel="alternate" type="text/html" title="[Udacity] Deep Learning (7) - CNN 구성과 LeNet-5(작성중)" /><published>2021-07-05T01:11:24+09:00</published><updated>2021-07-05T01:11:24+09:00</updated><id>https://refstop.github.io/uda-lenet</id><content type="html" xml:base="https://refstop.github.io/uda-lenet.html">&lt;p&gt;지난 게시글에 이어 CNN의 구성과 LeNet-5를 예시로 파라미터를 계산해 보겠습니다.&lt;/p&gt;
&lt;h2 id=&quot;1-cnn의-구성&quot;&gt;1. CNN의 구성&lt;/h2&gt;
&lt;p&gt;CNN의 구성을 공부하는 예시로서 대표적으로 사용되는 LeNet-5 모델으로 정리하겠습니다.&lt;/p&gt;
&lt;h3 id=&quot;lenet-5-네트워크란&quot;&gt;LeNet-5 네트워크란?&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;100%&quot; height=&quot;100%&quot; src=&quot;/assets/img/deeplearning/lenet.png&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;LeNet-5 네트워크는 CNN을 처음으로 개발한 Yann Lecun 연구팀이 개발한 CNN 알고리즘의 이름입니다. 이 알고리즘이 소개된 논문 제목은 Gradient-based learning applied to document recognition”입니다.&lt;br /&gt;
LeNet-5 네트워크는 Input-C1-S2-C3-S4-C5-F6-Output으로 이루어져 있고, Convolution layer, Pooling layer 두 쌍과 Fully Connected layer 3개로 구성되어 있습니다. 원래 논문에서는 활성화 함수로서 tanh 함수를 사용했지만, 제 코드에서는 ReLU 함수를 사용하였습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras.models import Sequential
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten

model = keras.Sequential()

model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))
model.add(layers.MaxPooling2D())

model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))
model.add(layers.MaxPooling2D())

model.add(layers.Flatten())

model.add(layers.Dense(units=120, activation='relu'))

model.add(layers.Dense(units=84, activation='relu'))

model.add(layers.Dense(units=10, activation = 'softmax')) # class 개수에 맞게
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;실제 사용결과는 나중에 올리도록 하겠습니다….&lt;/p&gt;</content><author><name>Refstop</name></author><category term="Udacity" /><category term="Deep Learning" /><summary type="html">지난 게시글에 이어 CNN의 구성과 LeNet-5를 예시로 파라미터를 계산해 보겠습니다. 1. CNN의 구성 CNN의 구성을 공부하는 예시로서 대표적으로 사용되는 LeNet-5 모델으로 정리하겠습니다. LeNet-5 네트워크란? LeNet-5 네트워크는 CNN을 처음으로 개발한 Yann Lecun 연구팀이 개발한 CNN 알고리즘의 이름입니다. 이 알고리즘이 소개된 논문 제목은 Gradient-based learning applied to document recognition”입니다. LeNet-5 네트워크는 Input-C1-S2-C3-S4-C5-F6-Output으로 이루어져 있고, Convolution layer, Pooling layer 두 쌍과 Fully Connected layer 3개로 구성되어 있습니다. 원래 논문에서는 활성화 함수로서 tanh 함수를 사용했지만, 제 코드에서는 ReLU 함수를 사용하였습니다. ``` from keras.models import Sequential from keras.layers.convolutional import Conv2D from keras.layers.convolutional import MaxPooling2D from keras.layers import Dense from keras.layers import Flatten</summary></entry><entry><title type="html">[Udacity] Deep Learning (6) - Convolutional Nerual Network</title><link href="https://refstop.github.io/uda-cnn.html" rel="alternate" type="text/html" title="[Udacity] Deep Learning (6) - Convolutional Nerual Network" /><published>2021-07-04T15:41:24+09:00</published><updated>2021-07-04T15:41:24+09:00</updated><id>https://refstop.github.io/uda-cnn</id><content type="html" xml:base="https://refstop.github.io/uda-cnn.html">&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;100%&quot; height=&quot;100%&quot; src=&quot;/assets/img/deeplearning/cnn.png&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;지금까지 우리는 심층 신경망(Deep Nerual Network)을 구성하기까지의 과정을 살펴보았습니다. 이제 이 심층 신경망으로 구성할 수 있는 네트워크 중 이미지 학습에 최적화된 &lt;strong&gt;합성곱 신경망(Convolutional Nerual Network, CNN)&lt;/strong&gt;에 대해서 알아보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;cnn이-되기까지&quot;&gt;CNN이 되기까지&lt;/h2&gt;
&lt;p&gt;CNN이 고안되기 전에는 이미지를 Fully Connected Nerual Network라는 1차원 벡터 형태의 데이터를 학습하는 형태의 신경망 구조를 사용했습니다. 하지만 FNN은 몇 가지 단점이 있습니다.&lt;br /&gt;
 첫번째로 이미지 데이터를 평면화 시키는 과정에서 이미지의 인접한 픽셀 간의 정보가 유실된다는 점입니다. FNN은 1차원 벡터 형태의 데이터를 입력받기 때문에 이미지의 인접 픽셀간의 상관관계를 반영할 수 없습니다. 반면 CNN은 이미지의 특징을 보존한 채로 학습을 진행하기 때문에 인접 픽셀간의 정보 유식을 막을 수 있습니다.&lt;br /&gt;
 두번째 FNN의 문제점은 막대한 양의 model parameter입니다. 만약 FNN을 사용하여 (1024,1024)크기의 컬러 이미지를 처리하고자 한다면 FNN에 입력되는 벡터의 차원은 1024$\times$1024$\times$3=315만 개입니다. 약 300만 차원의 데이터를 처리하기 위해서는 막대한 양의 뉴런이 필요하고 이에 따라 model parameter의 개수는 더욱 많은 양이 필요할 것입니다. 하지만 CNN의 경우 필터들을&lt;/p&gt;

&lt;h2 id=&quot;1-cnn의-주요-용어-정리&quot;&gt;1. CNN의 주요 용어 정리&lt;/h2&gt;
&lt;p&gt;CNN에는 다음과 같은 용어들이 사용됩니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Convolution(합성곱)&lt;/li&gt;
  &lt;li&gt;채널(Channel)&lt;/li&gt;
  &lt;li&gt;필터(Filter)&lt;/li&gt;
  &lt;li&gt;커널(Kernel)&lt;/li&gt;
  &lt;li&gt;스트라이드(Stride)&lt;/li&gt;
  &lt;li&gt;패딩(Padding)&lt;/li&gt;
  &lt;li&gt;피처 맵(Feature Map)&lt;/li&gt;
  &lt;li&gt;액티베이션 맵(Activation Map)&lt;/li&gt;
  &lt;li&gt;풀링(Pooling) 레이어
각 용어에 대해서 간략하게 정리하겠습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;11-convolution-layer합성곱&quot;&gt;1.1 Convolution Layer(합성곱)&lt;/h3&gt;
&lt;p&gt;Convolution은 합성곱이라는 의미인데, input 함수(신호)와 임펄스 응답 함수(신호)를 반전 이동한 값을 곱하여 적분한 값입니다. 원래의 의미는 이렇지만, 이해하기 너무 어려우므로 다음 gif 파일을 통해 쉽게 알 수 있습니다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;80%&quot; height=&quot;80%&quot; src=&quot;/assets/img/deeplearning/conv.gif&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;위의 gif 파일은 입력된 이미지 데이터를 필터를 통해 Feature Map을 만드는 과정입니다. 필터로 이미지를 훑어가면서 각각의 합성곱 결과를 저장하여 Feature Map을 구성합니다. CNN의 첫번째 과정인 Convolution Layer는 바로 이 Feature Map을 생성하는 과정입니다. Feature Map을 생성한 후 활성화 함수(Activation Function)에 통과시킨 출력을 액티베이션 맵(Activation Map)이라고 합니다.&lt;/p&gt;

&lt;h3 id=&quot;12-채널channel&quot;&gt;1.2 채널(Channel)&lt;/h3&gt;
&lt;p&gt;채널은 이미지를 구성하고 있는 실수값의 차원입니다. 이미지를 색 공간에 따라서 분리할 때, RGB의 3채널로 분리할 수 있습니다. 이미지를 구성하는 각 픽셀은 실수로 표현한 3차원 데이터입니다. 각각의 차원은 R, G, B의 3색을 나타내는 실수로, 이때의 RGB를 채널이라고 합니다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;80%&quot; height=&quot;80%&quot; src=&quot;/assets/img/deeplearning/channel.jpg&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;Convolution Layer에 입력되는 데이터는 필터가 적용되고, 하나의 필터당 하나의 Feature Map이 생성됩니다. 따라서 Convolution Layer에 n개의 필터가 적용된다면 출력되는 Feature Map은 n개의 채널을 갖게 됩니다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;80%&quot; height=&quot;80%&quot; src=&quot;/assets/img/deeplearning/nfeaturemap.png&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;하지만 이번 게시글에서는 필터의 개수가 1개뿐인 모델만 다룰 것입니다.&lt;/p&gt;

&lt;h3 id=&quot;13-필터filter-커널kernel--스트라이드stride&quot;&gt;1.3 필터(Filter), 커널(Kernel) &amp;amp; 스트라이드(Stride)&lt;/h3&gt;
&lt;p&gt;필터는 이미지의 특징을 찾아내기 위한 공용 파라미터입니다. 일반적으로 (4,4), (3,3)같은 정방행렬로 표현되고 사용 방법은 1.1의 gif 이미지에 잘 표현되어 있습니다. 필터는 이미지를 순회하면서 합성곱을 계산하여 Feature Map을 생성합니다. 이때 필터가 한번에 이동하는 간격을 Stride라고 합니다. Stride는 직역하면 보폭이라는 뜻으로 말 그대로 “필터가 한 걸음에 얼마나 가냐”를 의미하는 값입니다. 위의 gif 이미지의 Stride는 1입니다. 아래 이미지는 Stride가 1이고, 이미지 픽셀이 (16,16), 필터 크기가 (2,2)일때의 Feature Map 생성 과정을 나타낸 사진입니다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;80%&quot; height=&quot;80%&quot; src=&quot;/assets/img/deeplearning/filter.jpg&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;입력 데이터가 여러 채널을 갖는 경우, 각 채널의 Feature Map을 모두 더한 값이 최종 출력이 됩니다. 따라서 입력 데이터의 채널 수와는 상관없이 필터의 개수에 따라 결정된다는 것을 알 수 있습니다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;80%&quot; height=&quot;80%&quot; src=&quot;/assets/img/deeplearning/channelfeaturemap.jpg&quot; /&gt;
&lt;/p&gt;

&lt;h3 id=&quot;14-패딩padding&quot;&gt;1.4 패딩(padding)&lt;/h3&gt;
&lt;p&gt;패딩은 Convolution layer에서 필터와 Stride의 작용으로 출력 Feature Map의 크기가 줄어드는 현상을 방지하고 출력 데이터의 사이즈를 조정하는 방법입니다. 단어 그대로 입력데이터에 패드를 부착하는 것처럼 이미지 외곽에 지정된 픽셀만큼 특정 값으로 채워넣습니다. 보통 CNN에서는 패딩값을 0으로 채웁니다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;80%&quot; height=&quot;80%&quot; src=&quot;/assets/img/deeplearning/padding.png&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;위의 이미지는 원래 입력 데이터 32$\times$32$\times$3 이미지에 2픽셀만큼의 패딩을 추가하여 36$\times$36$\times$3 이미지로 만든 것입니다. 출력 데이터의 사이즈를 조절하는 기능 이외에도 Convolution layer가 이미지의 외곽을 인식하는 학습 효과도 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;15-pooling-layer&quot;&gt;1.5 Pooling Layer&lt;/h3&gt;
&lt;p&gt;Pooling layer는 Convolution layer의 출력인 Activation Map을 입력으로 받아서 크기를 줄이거나 특정 데이터를 강조하는 용도로 사용됩니다. Pooling 처리 과정은 지정된 정방행렬 범위 내의 데이터를 Pooling 방식에 따라서 처리합니다. Pooling layer를 처리하는 방법으로는 Max pooling, Min pooling, Average pooling이 있습니다. 이름만 봐도 알 수 있듯이 각각 최댓값, 최솟값, 평균값만을 남기거나 계산하는 방식입니다. 다음 이미지를 참고하면 이해하기 쉽습니다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;80%&quot; height=&quot;80%&quot; src=&quot;/assets/img/deeplearning/maxpooling.png&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;Pooling layer의 처리과정은 Convolution layer와 거의 비슷하지만 조금의 차이점이 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;학습대상 파라미터가 없음&lt;/li&gt;
  &lt;li&gt;행렬의 사이즈 감소&lt;/li&gt;
  &lt;li&gt;채널 수 변경 없음
CNN에서는 주로 Max pooling을 사용합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-레이어별-출력-데이터-계산&quot;&gt;2. 레이어별 출력 데이터 계산&lt;/h2&gt;
&lt;p&gt;Convolution layer와 Pooling layer의 출력 데이터 크기를 계산하는 방법을 정리했습니다.&lt;/p&gt;
&lt;h3 id=&quot;21-convolution-layer-출력-데이터-크기-계산&quot;&gt;2.1 Convolution layer 출력 데이터 크기 계산&lt;/h3&gt;
&lt;p&gt;입력 데이터에 대한 필터의 크기와 Stride 크기에 따라서 Feature Map 크기가 결정됩니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;입력 데이터 높이: H&lt;/li&gt;
  &lt;li&gt;입력 데이터 폭: W&lt;/li&gt;
  &lt;li&gt;필터 높이: FH&lt;/li&gt;
  &lt;li&gt;필터 폭: FW&lt;/li&gt;
  &lt;li&gt;Stride 크기: S&lt;/li&gt;
  &lt;li&gt;Padding 사이즈: P&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;$Output\;Height=OH=\frac{(H+2P-FH)}{S}+1$&lt;/center&gt;
&lt;center&gt;$Output\;Width=OW=\frac{(W+2P-FW)}{S}+1$&lt;/center&gt;
&lt;p&gt;위 식의 결과는 자연수가 되어야 합니다. 또한 Convolution layer 다음에 Pooling layer가 온다면, Feature Map의 행과 열 크기는 Pooling 크기의 배수여야 합니다. 만약 Pooling 사이즈가 (3,3)이라면 위 식의 결과는 자연수이고 3의 배수여야 합니다. 이 조건을 만족하도록 Filter의 크기, Stride의 간격, Pooling 크기 및 패딩 크기를 조절해야 합니다.&lt;/p&gt;

&lt;h3 id=&quot;22-pooling-layer-출력-데이터-크기-계산&quot;&gt;2.2 Pooling layer 출력 데이터 크기 계산&lt;/h3&gt;
&lt;p&gt;Pooling layer의 Pooling 사이즈는 일반적으로 정방행렬입니다. 또한 Convolution layer의 출력이 Pooling 사이즈의 정수배가 되도록 하여 Pooling layer의 출력 사이즈를 결정하게 됩니다. 예를 들어 Convolution layer의 출력 Activation Map 사이즈가 (6,6)이고 Pooling 사이즈가 (3,3)이면, Pooling layer의 출력 사이즈는 (2,2)가 됩니다. 따라서 Pooling layer의 출력 사이즈는 다음과 같이 계산할 수 있습니다.&lt;/p&gt;
&lt;center&gt;$Output\;Row\;Size=\frac{Input\;Row\;Size}{Pooling\;Size}$&lt;/center&gt;
&lt;center&gt;$Output\;Column\;Size=\frac{Input\;Column\;Size}{Pooling\;Size}$&lt;/center&gt;

&lt;h2 id=&quot;마무리&quot;&gt;마무리&lt;/h2&gt;
&lt;p&gt;이번 게시글에서는 CNN에서 사용되는 용어 및 입출력 데이터의 크기를 계산하는 방법을 알아보았습니다. 다음 게시글은 이 게시글에 이어 LeNet-5 네트워크 구성과 직접적인 예시를 들어 파라미터를 계산해 보도록 하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;참고-사이트&quot;&gt;참고 사이트&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://taewan.kim/post/cnn/&quot;&gt;TAEWAN.KIM 블로그 - “CNN, Convolutional Neural Network 요약”&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://untitledtblog.tistory.com/150&quot;&gt;Untitled 블로그 - “[머신 러닝/딥 러닝] 합성곱 신경망 (Convolutional Neural Network, CNN)과 학습 알고리즘”&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://yjjo.tistory.com/8&quot;&gt;YJJo 블로그 - “Convolution Nerual Networks (합성곱 신경망)”&lt;/a&gt;&lt;/p&gt;</content><author><name>Refstop</name></author><category term="Udacity" /><category term="Deep Learning" /><summary type="html">지금까지 우리는 심층 신경망(Deep Nerual Network)을 구성하기까지의 과정을 살펴보았습니다. 이제 이 심층 신경망으로 구성할 수 있는 네트워크 중 이미지 학습에 최적화된 합성곱 신경망(Convolutional Nerual Network, CNN)에 대해서 알아보겠습니다.</summary></entry><entry><title type="html">Indoor 2D Navigation - 개요 &amp;amp; 좌표범위내 신호 출력 노드</title><link href="https://refstop.github.io/i2n-signal.html" rel="alternate" type="text/html" title="Indoor 2D Navigation - 개요 &amp;amp; 좌표범위내 신호 출력 노드" /><published>2021-03-02T12:41:24+09:00</published><updated>2021-03-02T12:41:24+09:00</updated><id>https://refstop.github.io/i2n-signal</id><content type="html" xml:base="https://refstop.github.io/i2n-signal.html">&lt;h1 id=&quot;프로젝트의-목적&quot;&gt;프로젝트의 목적&lt;/h1&gt;
&lt;p&gt;본 프로젝트의 목적은 Kobuki 로봇을 사용하여 대학의 로봇관 건물을 자율주행 할 수 있도록 여러 SLAM 기법이나 Navigation 패키지를 사용해 보고, ROS 패키지를 제작하여 ROS와 우분투 환경에 익숙해지는 것입니다. 차후 있을 3D 라이다를 사용한 실내 자율주행 로봇 과제 등을 수행하기 위해 기본적인 사용법을 익히는 것을 목표로 하고 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;프로젝트-계획&quot;&gt;프로젝트 계획&lt;/h1&gt;
&lt;p&gt;프로젝트의 진행 계획은 다음과 같습니다. 이 계획은 진행 상황에 따라 수정될 수 있습니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Kobuki 패키지 작성&lt;/li&gt;
  &lt;li&gt;map에서 특정 좌표를 기준으로 일정 범위 내에 위치하면 신호 출력 노드&lt;/li&gt;
  &lt;li&gt;좌표를 파라미터화(yaml, dynamic_reconfigure)&lt;/li&gt;
  &lt;li&gt;gmapping, cartographer mapping 실습&lt;/li&gt;
  &lt;li&gt;amcl, cartographer pure localization을 사용한 localization&lt;/li&gt;
  &lt;li&gt;move_base를 사용한 자율주행&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;패키지-작성-전-prerequisite&quot;&gt;패키지 작성 전 Prerequisite&lt;/h1&gt;
&lt;h2 id=&quot;1-kobuki-패키지-설치&quot;&gt;1. Kobuki 패키지 설치&lt;/h2&gt;
&lt;p&gt;Kobuki 운용을 위해서는 Kobuki 패키지 설치를 해야합니다. 기존에 사용하던 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catkin_ws&lt;/code&gt;를 사용해도 되지만 저는 새로운 작업공간 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kobuki_ws&lt;/code&gt;를 생성했습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ mkdir -p kobuki_ws/src
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;그 후 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;src&lt;/code&gt;폴더에 Kobuki 패키지를 설치합니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cd kobuki_ws/src
$ git clone https://github.com/yujinrobot/kobuki.git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이때 이 Kobuki 패키지에 필요한 ROS 패키지들을 설치하기 위해 다음의 명령어를 통해 패키지들을 설치합니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo apt-get install ros-melodic-kobuki*
$ sudo apt-get install ros-melodic-ecl*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;마지막으로 의존성을 설치하여 마무리합니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cd ~/kobuki_ws
$ rosdep install --from-paths src --ignore-src -r -y
$ catkin_make
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;2-turtlebot3-패키지-설치-선택&quot;&gt;2. Turtlebot3 패키지 설치 (선택)&lt;/h2&gt;
&lt;p&gt;패키지를 작성할 때 Turtlebot3 패키지를 참고할 일이 많기 때문에 Turtlebot3 패키지를 설치해 두는 편이 좋습니다. 직접적인 사용은 하지 않을 것이기에, 설치하기 싫다면 필요할 때마다 &lt;a href=&quot;https://github.com/ROBOTIS-GIT/turtlebot3.git&quot;&gt;Turtlebot3 github 링크&lt;/a&gt;를 참고해도 괜찮습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cd ~/kobuki_ws/src
$ git clone -b melodic-devel --single-branch https://github.com/ROBOTIS-GIT/turtlebot3.git
$ cd ~/kobuki_ws
$ rosdep install --from-paths src --ignore-src -r -y
$ catkin_make
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;map에서-특정-좌표-범위-내-위치시-신호-출력-노드&quot;&gt;map에서 특정 좌표 범위 내 위치시 신호 출력 노드&lt;/h1&gt;
&lt;p&gt;첫번째로 저희가 시도한 것은 map의 특정 좌표를 주고, 로봇이 그 좌표로부터 일정 범위 내에 들어가면 신호를 보내는 것이었습니다. map 좌표계로부터 로봇의 base_link(base_footprint) 좌표계로 transform(좌표계 변환)하여 map 좌표계를 기준으로 로봇이 어느 좌표에 있는지를 알 수 있습니다.&lt;/p&gt;
&lt;center&gt; &lt;iframe width=&quot;560&quot; height=&quot;400&quot; src=&quot;https://youtu.be/pEbvt-Pv_hU&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt; &lt;/center&gt;
&lt;p&gt;사실 조금 진행된 프로젝트라서 이미 앞서 정리할 여러 기능들이 추가되어 있습니다. 동영상에 나오는 기능은 신호 출력 노드와 dynamic reconfigure(동적 파라미터 수정), 그 외에 Kobuki를 조종하거나 lidar 동작 기능을 포함하였습니다.&lt;/p&gt;

&lt;h1 id=&quot;좌표를-파라미터화-yaml-dynamic-reconfigure&quot;&gt;좌표를 파라미터화 (yaml, dynamic reconfigure)&lt;/h1&gt;
&lt;h2 id=&quot;yaml-파일-작성&quot;&gt;yaml 파일 작성&lt;/h2&gt;
&lt;p&gt;yaml 파일은 패키지의 설정값을 저장하는 파일입니다. 노드는 이 파일을 참고하여 소스에 값을 전달합니다. 예를 들어 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;point.yaml&lt;/code&gt; 파일의 내용물이 다음과 같다고 합시다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x: 13
y: 20
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;저희가 만든 패키지의 소스에 필요한 특정 좌표 부분을 yaml 파일로 작성한 것입니다. 노드를 실행하였을 때, 자동으로 yaml 파일을 참고하여 $x$, $y$ 값을 가져오면, 매번 소스를 건드리지 않고도 설정을 바꿔 줄 수 있습니다. 하지만 yaml 파일을 수정할 때 마다 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catkin_make&lt;/code&gt;를 다시 해 주어야 하니 번거롭기는 합니다.&lt;/p&gt;

&lt;h2 id=&quot;dynamic-reconfigure&quot;&gt;dynamic reconfigure&lt;/h2&gt;
&lt;p&gt;dynamic reconfigure는 동적 파라미터 수정으로, 노드에 설정되는 파라미터를 수정해 줌으로서 프로그램 실행 중에도 계속 파라미터를 바꿀 수 있도록 하는 도구입니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rosparam&lt;/code&gt; 명령어 또는 yaml 파일로도 계속하여 수정해 줄 수 있지만 매번 명령어를 치거나 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catkin_make&lt;/code&gt;를 해야 하는 번거로움이 있습니다. dynamic reconfigure는 GUI를 지원하는 rqt를 통해 수정할 수 있습니다. 이번 프로젝트 같은 경우 처음에는 특정 좌표를 소스 상에서 설정해 주었으나, dynamic reconfigure 기능을 통해 좌표를 계속해서 재설정할 수 있도록 기능을 추가하였습니다. 소스는 다음과 같습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(소스)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;다음-게시글&quot;&gt;다음 게시글&lt;/h1&gt;
&lt;p&gt;오랜만에 게시글을 수정하여 바뀐 점이 많습니다. 우선 다음 게시글에서는 Cartographer 사용법에 관하여 정리하도록 하겠습니다.&lt;/p&gt;</content><author><name>Refstop</name></author><category term="실내 자율 주행" /><category term="Kobuki" /><summary type="html">프로젝트의 목적 본 프로젝트의 목적은 Kobuki 로봇을 사용하여 대학의 로봇관 건물을 자율주행 할 수 있도록 여러 SLAM 기법이나 Navigation 패키지를 사용해 보고, ROS 패키지를 제작하여 ROS와 우분투 환경에 익숙해지는 것입니다. 차후 있을 3D 라이다를 사용한 실내 자율주행 로봇 과제 등을 수행하기 위해 기본적인 사용법을 익히는 것을 목표로 하고 있습니다.</summary></entry><entry><title type="html">[Udacity] Deep Learning (5) - Deep Nerual Network</title><link href="https://refstop.github.io/uda-dnn.html" rel="alternate" type="text/html" title="[Udacity] Deep Learning (5) - Deep Nerual Network" /><published>2021-03-02T12:34:24+09:00</published><updated>2021-03-02T12:34:24+09:00</updated><id>https://refstop.github.io/uda-dnn</id><content type="html" xml:base="https://refstop.github.io/uda-dnn.html">&lt;h1 id=&quot;deep-nerual-network&quot;&gt;Deep Nerual Network&lt;/h1&gt;
&lt;p&gt;지금까지 정리한 Nerual Network는 모두 layer가 하나뿐인 단층 신경망(Single-Layer Perceptron)입니다. 하지만 단층 신경망으로는 비선형 모델을 구현할 수 없습니다. &lt;a href=&quot;https://refstop.github.io/udacity/deep%20learning/uda-dl-nnnl#1&quot;&gt;지난 게시글&lt;/a&gt;에서 언급한 바와 같이 비선형 모델은 입력층(Input layer), 은닉층(Hidden layer), 출력층(Output layer)으로 이루어진 $^{1)}$심층 신경망(Deep Neural Network)으로 구현할 수 있습니다. 따라서 인공 신경망의 성능 향상을 위해서는 심층 신경망의 사용은 필수적이라고 할 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;relu-activation-function&quot;&gt;ReLU Activation Function&lt;/h2&gt;
&lt;p&gt;심층 신경망에 대해서 정리하기 전에 &lt;strong&gt;ReLU 활성화 함수&lt;/strong&gt;에 대해서 알아보고 넘어가겠습니다. 활성화 함수는 각 층의 신경망의 출력을 결정하는 함수입니다. 또한 활성화 함수가 없다면 심층 신경망은 $y=W_{1}W_{2}W_{3} \cdots x=Wx$가 되므로 비선형 모델이라고 볼 수 없는 결과가 나옵니다. 이러한 문제를 해결하기 위해서 넣은 활성화 함수이지만, 지금까지 우리가 잘 사용했던 Sigmoid 활성화 함수에는 단점이 있습니다. 다음은 Sigmoid 함수의 미분 그래프를 나타낸 것입니다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;70%&quot; height=&quot;70%&quot; src=&quot;/assets/img/deeplearning/sigmoid_deriv.png&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;Sigmoid 함수의 단점은 미분값의 범위가 0~0.25라는 점입니다. &lt;a href=&quot;https://refstop.github.io/udacity/deep%20learning/uda-dl-nnnl#3&quot;&gt;Cross-Entropy 오차 역전파 방법&lt;/a&gt;을 사용할 때, 활성화 함수의 미분값을 곱해주게 됩니다. 이때 활성화 함수의 미분값이 항상 1보다 작은 경우, 바로 Sigmoid 함수같은 경우 심층 신경망의 layer가 많을수록 오차에 대한 가중치의 미분, 즉 가중치가 오차에 영향을 미치는 성분이 점점 작아지고, layer가 너무 많은 경우 오차의 미분값이 0에 수렴하게 됩니다. 이 현상이 바로 &lt;strong&gt;기울기 소실(Gradient Vanishing)&lt;/strong&gt;입니다.&lt;/p&gt;

&lt;p&gt;이러한 점을 해결하기 위해서 사용하는 활성화 함수가 바로 &lt;strong&gt;ReLU(Rectified Linear Unit)&lt;/strong&gt; 함수입니다. ReLU함수의 그래프는 다음과 같은 형태입니다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;70%&quot; height=&quot;70%&quot; src=&quot;/assets/img/deeplearning/relu.png&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;기울기 소실의 근본적인 문제점은 Sigmoid 함수의 미분값 범위 0~0.25 때문에 발생했습니다. 하지만 ReLU 함수는 활성화되었을 때 값이 1, 비활성화 되었을 때 값이 0이므로 기울기 소실 문제를 해결할 수 있습니다. 역전파 연산의 결과값, 즉 가중치에 대한 오차의 미분값이 작아지지 않기 때문에 layer 개수에 관계없이 역전파 연산의 결과를 얻을 수 있습니다. 실제로 가장 많이 사용하는 활성화 함수 역시 ReLU 함수입니다.&lt;/p&gt;

&lt;h2 id=&quot;다시-심층-신경망의-본론으로&quot;&gt;다시 심층 신경망의 본론으로….&lt;/h2&gt;
&lt;p&gt;방금 알아본 바와 같이 ReLU 활성화 함수를 사용하여 심층 신경망을 구성합니다. 구성된 신경망의 형태는 이전 게시글의 &lt;a href=&quot;https://refstop.github.io/udacity/deep%20learning/uda-dl-nnnl#1&quot;&gt;비선형 모델 - 다층 신경망&lt;/a&gt;의 그림과 별 다를 바가 없지만, 아무래도 괴발개발 그린 그림(…)보다는 구글에서 퍼온 그림이 눈이 편할 것 같아 준비했습니다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;80%&quot; height=&quot;80%&quot; src=&quot;/assets/img/deeplearning/Neuron.png&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;먼저 각각의 뉴런의 구성을 그린 이미지를 준비했습니다. 위의 이미지가 바로 layer가 하나뿐인 신경망, 단층 신경망입니다. 이전 게시글에 정리했던 내용이지만, 저도 오랜만에 작성하다 보니 복습할 이미지가 필요했습니다. 이러한 뉴런을 이어붙여 만든 신경망은 다음과 같습니다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;80%&quot; height=&quot;80%&quot; src=&quot;/assets/img/deeplearning/shallowNN.png&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;은닉층(Hidden layer)이 하나뿐인 얕은 신경망(Shallow layer)입니다. 왠지 모르게 “얕은 신경망”이라는 이름이 붙어 있지만 그냥 은닉층 1단짜리 심층 신경망입니다. 왜 이런 이름이 있지? 제 생각이지만 은닉층 1층짜리밖에 구현 못하던 시절엔 이걸 심층 신경망이라 불렀는데 더 깊게 구성할 수 있는 기술이 개발된 후 진짜 심층 신경망과 구분하기 위해 지은 이름이 아닐까요? 제 생각일 뿐이니 한귀로 듣고 한귀로 흘리시길 바랍니다….&lt;br /&gt;
다음 그림은 위의 얕은 신경망에서 발전된 형태인 진짜배기 심층 신경망입니다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;80%&quot; height=&quot;80%&quot; src=&quot;/assets/img/deeplearning/dnn.png&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;이런 식으로 다수의 뉴런으로 심층 신경망을 구현하여 가중치를 구할 수 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;과적합-방지법&quot;&gt;과적합 방지법&lt;/h1&gt;
&lt;p&gt;과적합은 훈련 데이터에 모델이 과도하게 회귀되어 오히려 실제 사용에서 성능이 떨어지는 현상입니다. 훈련 데이터에 대한 노이즈까지 학습을 해버려서 일어나는 현상인데, 훈련 데이터에서는 높은 정확도를 보이지만 검증 데이터나 테스트 데이터에서는 제대로 동작하지 않습니다. 이러한 현상을 방지할 수 있는 방법에 대해서 정리하였습니다.&lt;/p&gt;

&lt;h2 id=&quot;1-데이터-양을-늘리기&quot;&gt;1. 데이터 양을 늘리기&lt;/h2&gt;
&lt;p&gt;과적합 뿐만 아니라 모델 자체의 성능을 높이는 데도 좋은 방법입니다. 심층 신경망 구조는 학습시킬 데이터가 많을수록 정확도가 올라가는 성질, 즉 데이터의 일반적인 패턴을 학습시키는 방법이라고 볼 수 있습니다. 노이즈가 있는 데이터와 없는 데이터를 모두 학습하며 모델이 좀 더 견고해지는 효과를 볼 수 있습니다.&lt;br /&gt;
 하지만 데이터가 항상 충분할 수는 없으므로 의도적으로 데이터를 변형하여 더 많은 학습 데이터를 생성하기도 하는데, 이를 데이터 증식 또는 증강(Data Augmentation)이라고 합니다. 이미지를 돌리거나 자르고, 노이즈를 추가하거나 밝기를 낮추는 식으로 데이터 갯수를 부풀리는 식의 방법입니다.&lt;/p&gt;

&lt;h2 id=&quot;2-데이터-정규화&quot;&gt;2. 데이터 정규화&lt;/h2&gt;
&lt;p&gt;데이터 정규화에는 $L1$ 정규화와 $L2$ 정규화가 있습니다. 이에 따라 필요한 용어부터 살펴보도록 하겠습니다.&lt;/p&gt;
&lt;h3 id=&quot;l1-norm--l2-norm&quot;&gt;$L1$ Norm &amp;amp; $L2$ Norm&lt;/h3&gt;
&lt;p&gt;$L1$ 정규화와 $L2$ 정규화를 설명하기에 앞서 $L1$, $L2$ Norm에 대해서 설명하겠습니다. 우선 Norm이란 것은 벡터의 거리를 측정하는 방법입니다. 이를 표현한 수식은 다음과 같습니다.&lt;/p&gt;
&lt;center&gt; $\left \| x \right \|_p:=\left (\sum_{i=1}^{n}\left | x_i \right |^p\right )^{1/p}$ &lt;/center&gt;
&lt;p&gt;이때 p값은 Norm의 차수를 의미합니다. $L1$, $L2$에 있는 숫자가 바로 p입니다. 이 공식에 따르면 $L1$ Norm과 $L2$ Norm은 다음과 같습니다.&lt;/p&gt;
&lt;center&gt; $p=(p_1, p_2, \cdots, p_n), q=(q_1, q_2, \cdots, q_n)$ 일 때, &lt;/center&gt;
&lt;center&gt; $L1\;Norm: \; \left \| x \right \|_1=\sum_{i=1}^{n}\left | p_i-q_i \right |$ &lt;/center&gt;
&lt;center&gt; $\begin{align*} L2\;Norm: \;\left \| x \right \|_2&amp;amp;=\left (\sum_{i=1}^{n}\left | p_i-q_i \right |^2\right )^{1/2} \\
&amp;amp;= \sqrt{(p_1-q_1)^2+(p_2-q_2)^2+\cdots+(p_n-q_n)^2}
\end{align*}$ &lt;/center&gt;
&lt;p&gt;$L1$ Norm은 각 $p,q$원소들 간의 직선거리입니다. $L2$ Norm은 $p, q$ 벡터 사이의 직선거리입니다.&lt;/p&gt;

&lt;h3 id=&quot;l1-loss--l2-loss&quot;&gt;$L1$ Loss &amp;amp; $L2$ Loss&lt;/h3&gt;
&lt;p&gt;이러한 방식으로 $L1$ Loss와 $L2$ Loss 함수를 구현할 수 있습니다. $p$ 벡터를 실제 값으로, $q$ 벡터를 예측치로 치환하면 두 식은 다음과 같습니다.&lt;/p&gt;
&lt;center&gt; $L1\;Loss=\sum_{i=1}^{n}\left | y_i-f(x_i) \right |$&lt;/center&gt;
&lt;center&gt; $L2\;Loss=\sum_{i=1}^{n}\left ( y_i-f(x_i) \right )^2$&lt;/center&gt;
&lt;p&gt;$L1$ Loss와 $L2$ Loss의 차이는 잘못된 값에 대해서 $L2$ Loss의 경우 오차의 제곱을 더해 주기 때문에 $L2$ Loss가 Outlier에 더 민감하다는 점입니다. 따라서 Outlier가 적당히 무시되길 원하면 $L1$ Loss를 사용하고, Outlier의 등장에 신경써야 한다면 $L2$ Loss를 사용하는 것이 좋습니다.&lt;/p&gt;

&lt;h2 id=&quot;l1-regularization--l2-regularization&quot;&gt;$L1$ Regularization &amp;amp; $L2$ Regularization&lt;/h2&gt;
&lt;p&gt;위의 Loss 함수를 원래 모델에서 사용하던 Cost 함수에 추가하면 다음과 같은 결과를 얻을 수 있습니다.&lt;/p&gt;
&lt;center&gt; $L1\;Regularization:\;\; cost(W,b)=\frac{1}{n} \sum_{i=1}^{n} \left \{ L(y_i,\hat{y_i})+\frac{\lambda}{2}\left | w \right |\right \}$ &lt;/center&gt;
&lt;center&gt; $L2\;Regularization:\;\; cost(W,b)=\frac{1}{n} \sum_{i=1}^{n} \left \{ L(y_i,\hat{y_i})+\frac{\lambda}{2}\left | w \right |^2\right \}$ &lt;/center&gt;
&lt;center&gt; $L(y_i,\hat{y_i}):$ 기존의 Cost function&lt;/center&gt;
&lt;p&gt;기존의 오차함수에 가중치의 크기가 포함되면서 가중치가 너무 큰 방향으로 학습되지 않도록 하는 항을 추가해 주었습니다. 이때 $\lambda$는 학습률로 정규화의 효과를 조절하는 항으로 사용됩니다.&lt;br /&gt;
$L1$ Regularization과 $L2$ Regularization의 차이는 $L2$ Regularization는 미분이 가능하여 Gradient-based learning이 가능하다는 점입니다.&lt;/p&gt;

&lt;h2 id=&quot;3-dropout&quot;&gt;3. Dropout&lt;/h2&gt;
&lt;p&gt;Dropout은 의도적으로 은닉층의 일정 비율을 일부러 학습하지 않아 새로운 Epoch마다 조금씩 특징이 다른 데이터 셋을 학습시키는 효과를 내는 방법입니다. 여러 개의 모델을 만들지 않고도 모델 결합이 여러 형태를 가지게 하는 것입니다. 네트워크를 학습하는 동안 랜덤하게 일부 유닛이 동작하는 것을 생략한다면 뉴런의 조합만큼 지수함수적으로 다양한 모델을 학습시키는 것과 같습니다. n개의 유닛이 있다고 하면 $2^n$개 만큼의 모델이 생성될 것입니다.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;80%&quot; height=&quot;80%&quot; src=&quot;/assets/img/deeplearning/dropout.png&quot; /&gt;
&lt;/p&gt;

&lt;h1 id=&quot;마무리&quot;&gt;마무리&lt;/h1&gt;
&lt;p&gt;이번 게시글에서는 DNN과 과적합을 방지하는 법에 대해서 정리했습니다. 다음 게시글은 Convolution Nerual Network과 LeNet에 대해서 정리하겠습니다.&lt;/p&gt;

&lt;h1 id=&quot;질문&quot;&gt;질문&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;은닉층을 Wide하게 만드는 것보다 Deeper하게 만드는 것이 좋은 이유가 무엇인가요? 모델이 자연스럽게 계층 구조를 가지게 된다는 의미를 잘 모르겠습니다. 계층별로 비슷한 녀석들끼리 모인다는 뜻인가요?&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;보충&quot;&gt;보충&lt;/h1&gt;
&lt;p&gt;1) 다층 신경망(Multi-layer Perceptron)이라고도 함&lt;/p&gt;

&lt;h1 id=&quot;참고-사이트&quot;&gt;참고 사이트&lt;/h1&gt;
&lt;p&gt;Udacity Self-driving car nanodegree - Deep Nerual Network(링크 공유 불가능)&lt;br /&gt;
&lt;a href=&quot;https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;amp;blogId=handuelly&amp;amp;logNo=221824080339&quot;&gt;답을 찾아가는 과정 - “딥러닝 - 활성화 함수(Activation) 종류 및 비교”&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://heung-bae-lee.github.io/2019/12/08/deep_learning_03/&quot;&gt;DataLatte’s IT Blog - “심층 신경망의 구조”&lt;/a&gt;&lt;/p&gt;</content><author><name>Refstop</name></author><category term="Udacity" /><category term="Deep Learning" /><summary type="html">Deep Nerual Network 지금까지 정리한 Nerual Network는 모두 layer가 하나뿐인 단층 신경망(Single-Layer Perceptron)입니다. 하지만 단층 신경망으로는 비선형 모델을 구현할 수 없습니다. 지난 게시글에서 언급한 바와 같이 비선형 모델은 입력층(Input layer), 은닉층(Hidden layer), 출력층(Output layer)으로 이루어진 $^{1)}$심층 신경망(Deep Neural Network)으로 구현할 수 있습니다. 따라서 인공 신경망의 성능 향상을 위해서는 심층 신경망의 사용은 필수적이라고 할 수 있습니다.</summary></entry><entry><title type="html">[Udacity] Deep Learning (4) - Tensorflow</title><link href="https://refstop.github.io/uda-dl-tensorflow.html" rel="alternate" type="text/html" title="[Udacity] Deep Learning (4) - Tensorflow" /><published>2021-03-01T21:14:35+09:00</published><updated>2021-03-01T21:14:35+09:00</updated><id>https://refstop.github.io/uda-dl-tensorflow</id><content type="html" xml:base="https://refstop.github.io/uda-dl-tensorflow.html">&lt;h1 id=&quot;왜-tensowflow-인가&quot;&gt;왜 Tensowflow 인가&lt;/h1&gt;
&lt;h2 id=&quot;tensorflow란&quot;&gt;Tensorflow란?&lt;/h2&gt;
&lt;p&gt;지난 시간까지 신경망을 쌓으면서 모델을 학습, 즉 적절한 가중치와 바이어스를 구하는 방법을 이론적으로 알아보았습니다. 이번 게시글에선 이 방법들을 물리적인 코드로 구현해 보겠습니다. 하지만 코드로 구현한다고 하여 덧셈 뺄셈 연산자를 이용하여 밑바닥부터 구현한다는 의미는 아닙니다. 이미 시중에는 딥러닝을 초보자도 쉽게(?) 구현할 수 있도록 제작해 놓은 여러 라이브러리들이 있습니다. 이 중 우리는 가장 많은 사람들이 사용하는 &lt;strong&gt;Tensorflow&lt;/strong&gt;를 사용할 것입니다.
&lt;img src=&quot;/assets/img/deeplearning/tensor flow.png&quot; alt=&quot;tensor flow&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;&lt;br /&gt;
Tensorflow는 구글에서 만든 딥러닝을 쉽게 구현할 수 있도록 기능을 제공하는 라이브러리입니다. 위 그림과 같이 딥러닝을 할 사용되는 텐서 형태의 데이터들이 모델을 구성하는 연산들의 그래프를 따라 흐르면서 연산이 일어납니다. 데이터를 의미하는 텐서(tensor)와 데이터 플로우 그래프를 따라 연산이 수행되는 형태인 flow를 합쳐 텐서플로(tensorflow)라고 부릅니다.&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-1-2&quot;&gt;Tensorflow 1? 2?&lt;/h2&gt;
&lt;p&gt;텐서플로는 현재 버전이 1과 2 두 가지가 있습니다. 두 버전의 차이는 다음과 같습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;placeholder, session 사용X&lt;/li&gt;
  &lt;li&gt;필요한 기능은 함수로 구현, @tf.function 사용&lt;/li&gt;
  &lt;li&gt;훨씬 간단하다!
아직 텐서플로를 많이 사용해 보지 못해 모든 차이점을 말할 수는 없지만 요점은 2가 1보다 훨씬 간단하다는 뜻입니다. 텐서플로 1은 코드를 죽 짠 후, 맨 마지막 실행 단계에서는 session이라는 class를 통해 실행을 시키게 됩니다. 하지만 이렇다 보니 실행 단계에서 session이라는 블랙박스에 가까운 공간 안에서 작업이 수행되다 보니 개발자가 개입하기가 힘들었습니다. 하지만 텐서플로 2에서는 session을 없애고 keras라는 강력한 라이브러리를 텐서플로 라이브러에서 편입시키면서 더욱 쓰기 편한 라이브러리가 되었습니다. 따라서 처음 시작하는 분들은 텐서플로 2로 시작하는 것을 추천하지만, 예전 소스를 참고하기 위해선 텐서플로 1을 읽을 수 있는 방법도 알아야 하기에, 어느정도 비율을 조정해서 병행하는 것이 좋다고 생각합니다.&lt;br /&gt;
제가 수강하는 Udacity 강의는 텐서플로 1을 사용하였기 때문에 이 게시글은 텐서플로 1의 문법으로 작성하겠습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;tensorflow-설치&quot;&gt;Tensorflow 설치&lt;/h1&gt;
&lt;p&gt;Tensorflow는 일반적으로 Anaconda라는 가상 환경에서 설치 후 실행합니다. 하지만 Anaconda는 파이썬 3 이상의 버전을 지원하기 때문에 파이썬 2 이하의 버전이 필요하신 분, 또는 다른 파이썬 라이브러리와 같이 사용해야 하는 분은 아나콘다 설치를 권장하지 않습니다. 저는 OpenCV도 함께 설치되어 있기 때문에 아나콘다를 통해 설치하지 않았습니다. 제가 시도해 본 방법은 다음과 같습니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;pip install&lt;/li&gt;
  &lt;li&gt;공식 홈페이지 whl 설치&lt;/li&gt;
  &lt;li&gt;Google Colab&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;1-pip-install-tensorflow&quot;&gt;1. pip install tensorflow&lt;/h2&gt;
&lt;p&gt;파이썬 패키지 라이브러리를 관리해주는 pip 명령어를 통해서 설치하는 방법입니다. 우분투로 치면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apt-get&lt;/code&gt; 명령어 정도의 포지션입니다. 일반적으로 파이썬을 설치했다면 설치되어 있겠지만, 혹시나 해서 설치 명령어를 남깁니다.&lt;br /&gt;
Python 2.X의 경우&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo apt-get install python-pip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Python 3.X의 경우&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo apt-get install python3-pip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;pip가 설치되어 있다면 다음 명령어를 통해 설치합니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ pip3 install tensorflow
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이 명령어는 기본적으로 텐서플로 최신 버전을 설치합니다. 원하는 버전이 있다면 끝에 ==X.XX를 붙이거나 텐서플로 패키지 이름을 명시하여 설치합니다.&lt;br /&gt;
예시)&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ pip3 install tensorflow==1.15
$ pip3 install tensorflow-gpu==1.15
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;참고로 텐서플로 2는 cpu 패키지와 gpu 패키지가 통합되어 있다고 합니다.&lt;/p&gt;

&lt;h2 id=&quot;2-공식-홈페이지-msi-설치&quot;&gt;2. 공식 홈페이지 msi 설치&lt;/h2&gt;
&lt;p&gt;위의 방법으로 설치는 할 수 있지만 개발 도구와 연동시키는 법을 몰라 저는 다음 방법으로 시도했습니다. 저는 Visual Studio Code로 코드를 작성하고 싶었기 때문에 whl 파일을 통해 설치했습니다. &lt;a href=&quot;https://www.tensorflow.org/install/pip?hl=ko&quot;&gt;공식 홈페이지 Tensorflow 설치 사이트&lt;/a&gt;에 가면 whl 파일을 받을 수 있는 링크가 있습니다. 저는 노트북에서 실행할 것이기 때문에 CPU만 지원하는 파일을 다운받았습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ wget https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow_cpu-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl
$ pip install tensorflow_cpu-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이 방법을 통하여 설치하면 VSC에서 텐서플로를 사용할 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;3-google-colab&quot;&gt;3. Google Colab&lt;/h2&gt;
&lt;p&gt;마지막 방법은 Google Colab을 사용하는 것입니다. 이 방법은 텐서플로를 내 컴퓨터에 설치하는 방법이 아니라 오프라인에서는 사용할 수 없지만, 구글에서 이미 준비가 다 된 환경을 마련해 준다는 편리함이 있습니다. 게다가 서버 역시 구글에서 제공하기 때문에 컴퓨터 성능과 관계없이 코드를 실행할 수 있습니다. 성능이 좋지는 않지만 예제 정도를 실행하거나 시간이 많다 하시는 분들은 이 방법도 추천합니다. 하지만 코랩에 기본적으로 설치된 텐서플로는 최신 버전이기 때문에 텐서플로 1을 사용하고 싶다면 별도로 삭제, 설치할 필요가 있습니다. 코랩용 삭제, 설치 코드는 다음과 같습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ !pip3 uninstall tensorflow
$ !pip3 install tensorflow==1.15
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;페이지를 나갔다가 다시 접속하면 매번 설치해 줘야 한다는 번거로움이 있습니다. 하지만 어디서나 실행할 수 있다는 편리함 때문에 용서해 주겠습니다. 코드는 또 텐서플로 2에 맞춰서 짜면 해결되는 부분이기도 하고요.&lt;/p&gt;

&lt;h1 id=&quot;tensorflow-1-기본-함수들&quot;&gt;Tensorflow 1 기본 함수들&lt;/h1&gt;
&lt;p&gt;텐서플로에서 사용하는 함수들에 대해서 알아보겠습니다.&lt;/p&gt;
&lt;h2 id=&quot;tfsession&quot;&gt;tf.Session()&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/deeplearning/session.png&quot; alt=&quot;session&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;br /&gt;
위에서 설명했듯이 작성한 코드를 실행하는 환경입니다. 먼저 코드를 짜고, Session에서 실행합니다. 하지만 텐서플로 2에서는 사용하지 않습니다.&lt;/p&gt;

&lt;h2 id=&quot;tfconstant&quot;&gt;tf.constant()&lt;/h2&gt;
&lt;p&gt;텐서 상수를 선언하는 함수입니다. 상수인 만큼 변하지 않는 텐서값입니다. 처음 정해준 값으로 끝까지 갑니다.&lt;br /&gt;
예시)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;import tensorflow as tf

hello_constant = tf.constant('Hello world!')

with tf.Session() as sess:
    hello = sess.run(hello_constant)
print(hello)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;출력:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;b'Hello world!'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;위의 코드와 같은 방식으로 tf.Session()을 사용합니다.&lt;/p&gt;

&lt;h2 id=&quot;tf사칙연산&quot;&gt;tf.사칙연산()&lt;/h2&gt;
&lt;p&gt;tf.add(), tf.multiply(), tf.subtract(), tf.divide() 함수가 있습니다. 덧셈, 곱셈, 뺄셈, 나눗셈 등 연산을 수행합니다. &lt;br /&gt;
예시)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;import tensorflow as tf

a = tf.constant(11)
b = tf.constant(5)
ad = tf.add(a, b)
sub = tf.subtract(a, b)
mul = tf.multiply(a, b)
div = tf.divide(a, b)

with tf.Session() as sess:
    r1 = sess.run(ad)
    r2 = sess.run(sub)
    r3 = sess.run(mul)
    r4 = sess.run(div)
print('add: {}\nsubtract: {}\nmultiply: {}\ndivide: {}'.format(r1, r2, r3, r4))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;출력:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;add: 16
subtract: 6
multiply: 55
divide: 2.2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;tfplaceholder&quot;&gt;tf.placeholder()&lt;/h2&gt;
&lt;p&gt;딥러닝에서 학습할 데이터를 담는 데이터 타입입니다. 학습용 데이터를 담는 그릇이라고 생각하면 됩니다. tf.Session()과 마찬가지로 텐서플로 2에서는 사용되지 않습니다.&lt;br /&gt;
예시)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;import tensorflow as tf

x = tf.placeholder(tf.int32, (None))
y = tf.placeholder(tf.int32, (None))
sum = tf.add(x, y)
with tf.Session() as sess:
  result = sess.run(sum, feed_dict={x: 11, y: 5})
print('sum: {}'.format(result))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;tfvariable-tfglobal_variables_initializer&quot;&gt;tf.Variable(), tf.global_variables_initializer()&lt;/h2&gt;
&lt;p&gt;상수와 초기화되지 않은 변수를 선언하는 방법을 보았으니 초기화와 동시에 변수를 선언하는 방법도 있습니다. 그것이 tf.Variable입니다. tf.global_variables_initializer()는 함수는 위의 코드에서 선언한 tf.Variable() 변수들을 세션에 적용해 주는 함수입니다. 예시는 다음과 같습니다.&lt;br /&gt;
예시)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;import tensorflow as tf

x = tf.Variable(5, name='x')

with tf.Session() as sess:
  sess.run(tf.global_variables_initializer())
  result = sess.run(x)
print('result: {}'.format(result))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;출력:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;result: 5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;tftruncated_normal&quot;&gt;tf.truncated_normal()&lt;/h2&gt;
&lt;p&gt;정규분포에서 랜덤 숫자를 뽑아내는 함수입니다. 주로 가중치를 초기화하는데 사용합니다. 가중치를 초기화할 때 정규분포를 사용하는 이유는 &lt;strong&gt;기울기 소실&lt;/strong&gt; 때문입니다. 가중치를 랜덤으로 주면 Sigmoid 함수의 출력값이 0 또는 1에 아주 가까운, 즉 0 또는 1로 근사할 수 있는 출력값이 나오게 됩니다.&lt;br /&gt;
&lt;img src=&quot;/assets/img/deeplearning/logistic.png&quot; alt=&quot;logistic&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;br /&gt;
이때, 출력값이 0 또는 1로 가게 된다면 Sigmoid 함수의 미분값이 0으로 치닫게 되므로, &lt;a href=&quot;https://refstop.github.io/posts/uda-dl-nncm/#cross-entropy%EC%9D%98-w-error-%EA%B7%B8%EB%9E%98%ED%94%84&quot;&gt;경사 하강법&lt;/a&gt;에서 활성화 함수인 Sigmoid 함수의 미분을 사용할 때 $\frac{\partial E}{\partial \sigma}\frac{\partial \sigma}{\partial z}\frac{\partial z}{\partial W}$ 중 $\frac{\partial \sigma}{\partial z}$의 값이 0이 되면서 가중치 수정값 역시 0이 됩니다.($z$는 선형 모델 결과값) 이렇게 오차함수의 기울기(Sigmoid 함수의 기울기)가 소실되는 현상을 &lt;strong&gt;기울기 소실(Gradient Vanishing Problem)&lt;/strong&gt;이라고 합니다.&lt;br /&gt;
따라서 정규분포로부터 랜덤 가중치를 뽑게 된다면, $-\infty ~ +\infty$ 사이의 숫자보다는 평균 0 근처의 숫자가 주로 추출될 것입니다. 이러한 특징을 통해 가중치가 한쪽으로 압도되는 것을 막을 수 있습니다.&lt;br /&gt;
예시)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;import tensorflow as tf

weights = tf.Variable(tf.truncated_normal(shape = (5, 5), mean = 0, stddev = 0.1))
with tf.Session() as sess:
  sess.run(tf.global_variables_initializer())
  result = sess.run(weights)
print('result:\n{}'.format(result))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;출력:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;result:
[[-0.01648159 -0.02329956  0.17793715 -0.06097916 -0.05726282]
 [ 0.14564233  0.14883497  0.01122501  0.08220296  0.06075064]
 [-0.0392657  -0.06555585 -0.00456797  0.00886977 -0.06788757]
 [-0.10041036  0.12152421  0.09188548  0.05627985 -0.11565887]
 [-0.04590392  0.03194086  0.09958582 -0.07237397 -0.06919689]]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;대부분 평균 0 근처의 난수가 저장된 것을 볼 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;tfzeros&quot;&gt;tf.zeros()&lt;/h2&gt;
&lt;p&gt;모든 텐서의 요소가 0인 텐서를 만드는 함수입니다. 바이어스를 초기화하는데 사용됩니다. 사용 방법은 weights 초기화 할때랑 비슷합니다.&lt;br /&gt;
예시)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;import tensorflow as tf

bias = tf.Variable(tf.zeros(6))
with tf.Session() as sess:
  sess.run(tf.global_variables_initializer())
  result = sess.run(bias)
print('result:\n{}'.format(result))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;출력:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;result:
[0. 0. 0. 0. 0. 0.]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;tensorflow-학습-함수들&quot;&gt;Tensorflow 학습 함수들&lt;/h1&gt;
&lt;h2 id=&quot;softmax&quot;&gt;Softmax&lt;/h2&gt;
&lt;p&gt;소프트맥스 함수는 logits라는 입력을 0~1 사이의 확률값으로 바꾸는 함수입니다. &lt;a href=&quot;https://refstop.github.io/posts/uda-dl-nncm/#softmax%EC%99%80-one-hot-encoding&quot;&gt;지난 게시글&lt;/a&gt;에 설명이 되어 있으니 자세한 설명은 생략하겠습니다. 사용 방법은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tf.nn.softmax(logits)&lt;/code&gt;입니다.&lt;/p&gt;

&lt;h2 id=&quot;cross-entropy&quot;&gt;Cross-Entropy&lt;/h2&gt;
&lt;p&gt;크로스 엔트로피는 학습에서 사용하는 오차함수입니다. 이 부분 역시 &lt;a href=&quot;https://refstop.github.io/posts/uda-dl-nncm/#3-cross-entropy-%EC%98%A4%EC%B0%A8%ED%95%A8%EC%88%98&quot;&gt;이 게시글&lt;/a&gt;에 설명되어 있으니 생략하겠습니다. 텐서플로에서의 사용법은 다음과 같습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = one_hot_y)
loss_operation = tf.reduce_mean(cross_entropy)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;optimization---최적화-단계&quot;&gt;Optimization - 최적화 단계&lt;/h1&gt;
&lt;p&gt;여기서 잠시 최적화 단계에 대해서 설명 드리겠습니다. 최적화는 모델 학습에서 가중치와 바이어스를 조절하는 단계를 의미합니다. 주로 경사 하강법을 사용합니다. 경사 하강법 역시 &lt;a href=&quot;https://refstop.github.io/posts/uda-dl-nncm/#4-gradient-descent&quot;&gt;지난번&lt;/a&gt;에 다루었기에 간단하게 설명하겠습니다. 오차함수의 미분을 통해 오차가 작아질 때까지 가중치 수정을 반복하는 알고리즘입니다. 오차함수의 기울기가 음수면 가중치를 증가, 양수면 가중치를 감소시킵니다. 하지만 경사하강법의 두 가지 문제점인 시간이 오래 걸린다와 지역 최솟값에 빠질 수 있다를 해결하기 위해 &lt;strong&gt;확률적 경사 하강법&lt;/strong&gt;과 &lt;strong&gt;모멘텀&lt;/strong&gt;이라는 방법이 고안되었습니다.&lt;/p&gt;

&lt;h2 id=&quot;stochastic-gradient-descentsgd-확률적-경사-하강법&quot;&gt;Stochastic Gradient Descent(SGD, 확률적 경사 하강법)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/deeplearning/sgd.png&quot; alt=&quot;sgd&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;br /&gt;
확률적 경사 하강법은 경사 하강법과는 다르게 랜덤으로 한개의 데이터만을 보고 계산하는 방법입니다. SGD의 장점은 적은 데이터로 학습할 수 있고 속도가 빠르다는 점입니다. 하지만 학습 중간 과정에서 결과의 진폭이 크고 불안정하며, 데이터를 하나씩 처리하기 때문에 GPU의 성능을 모두 활용하지 못한다는 단점을 가집니다. 따라서 이러한 단점을 보완하기 위해 Mini-Batch라는 방식을 사용합니다.&lt;br /&gt;
&lt;img src=&quot;/assets/img/deeplearning/mb sgd.png&quot; alt=&quot;mb sgd&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;br /&gt;
Mini Batch는 전체 학습데이터를 배치 사이즈로 나누어서 순차적으로 진행하는 방식입니다. Mini Batch SGD는 한개만 하던 그냥 SGD와는 다르게 데이터 일부분을 뽑아서 그 평균에 따라 가중치를 수정합니다. 이름에서도 알 수 있듯이 Mini Batch 방식과 SGD가 합쳐진 모습을 볼 수 있습니다. 병렬처리가 가능해지면서 GPU의 성능을 활용할 수도 있고 학습 중간 과정에서의 노이즈를 줄일 수 있습니다. 최근에는 거의 Mini Batch SGD를 사용하기 때문에 그냥 Mini Batch SGD를 SGD라고 부르기도 합니다.&lt;/p&gt;

&lt;h2 id=&quot;momentum모멘텀&quot;&gt;Momentum(모멘텀)&lt;/h2&gt;
&lt;p&gt;모멘텀은 지역 최솟값에 빠지지 않도록 고안된 방법입니다. 원래 경사 하강법에서는 오차함수를 미분한 값만큼만 가중치를 조정했지만, 모멘텀을 적용하면 이전 단계에서 오차함수의 미분값의 일부를 이번 단계에서도 적용하여 진짜 최솟값인지 아닌지를 한번 보는 원리로 표현할 수 있습니다. 수식으로 나타내면 다음과 같습니다.&lt;/p&gt;
&lt;center&gt;$\large{
v \leftarrow \alpha v-\eta \frac{\partial E}{\partial W}
}$&lt;/center&gt;
&lt;center&gt;$\large{
W \leftarrow W+v
}$&lt;/center&gt;
&lt;p&gt;여기서 $\alpha$로 이전 단계의 오차함수 미분값의 반영 비율을 조정합니다. 쉽게 설명하면 모멘텀, 즉 관성을 사용하여 원래 검사하려던 것보다 좀 더 멀리 뻗어보는 방법입니다.&lt;/p&gt;

&lt;h2 id=&quot;epoch&quot;&gt;Epoch&lt;/h2&gt;
&lt;p&gt;epoch는 전체 데이터 셋에 대해서 한번 학습을 완료한 상태를 의미합니다. 보통 Hyperparameter로 지정해 주게 되는데, Epoch은 배치를 사용하든 하지 않든 데이터의 전체 값을 모두 한번 본 상태여야 Epoch = 1인 상태라고 볼 수 있습니다. 결과적으로 전체 데이터 셋 학습 횟수로서 사용합니다. 예를 들어 EPOCH = 10이라고 지정해 줬다면 전체 데이터를 10번 학습하였다는 의미입니다.&lt;/p&gt;

&lt;h1 id=&quot;마무리&quot;&gt;마무리&lt;/h1&gt;
&lt;p&gt;Tensorflow에 대해서 알아보았지만 아직 많이 부족한 느낌입니다. 다음 게시글은 Deep Nerual Network를 정리할 예정입니다.&lt;/p&gt;

&lt;h1 id=&quot;질문&quot;&gt;질문&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;그럼 모멘텀으로 못빠져나올만큼 깊은 지역 최솟값일땐 어떻게 하나요?&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;참고-사이트&quot;&gt;참고 사이트&lt;/h1&gt;
&lt;p&gt;Udacity Self-driving car nanodegree - Tensorflow(링크 공유 불가능)&lt;br /&gt;
&lt;a href=&quot;https://www.tensorflow.org/install/pip?hl=ko&quot;&gt;Tensorflow 공식 홈페이지 - TensorFlow 설치&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://kolikim.tistory.com/48&quot;&gt;Broccoli’s House - #5-(2) 학습 관련 기술 : 초기 가중치 설정&lt;/a&gt;&lt;/p&gt;</content><author><name>Refstop</name></author><category term="Udacity" /><category term="Deep Learning" /><category term="Tensorflow" /><summary type="html">왜 Tensowflow 인가 Tensorflow란? 지난 시간까지 신경망을 쌓으면서 모델을 학습, 즉 적절한 가중치와 바이어스를 구하는 방법을 이론적으로 알아보았습니다. 이번 게시글에선 이 방법들을 물리적인 코드로 구현해 보겠습니다. 하지만 코드로 구현한다고 하여 덧셈 뺄셈 연산자를 이용하여 밑바닥부터 구현한다는 의미는 아닙니다. 이미 시중에는 딥러닝을 초보자도 쉽게(?) 구현할 수 있도록 제작해 놓은 여러 라이브러리들이 있습니다. 이 중 우리는 가장 많은 사람들이 사용하는 Tensorflow를 사용할 것입니다. Tensorflow는 구글에서 만든 딥러닝을 쉽게 구현할 수 있도록 기능을 제공하는 라이브러리입니다. 위 그림과 같이 딥러닝을 할 사용되는 텐서 형태의 데이터들이 모델을 구성하는 연산들의 그래프를 따라 흐르면서 연산이 일어납니다. 데이터를 의미하는 텐서(tensor)와 데이터 플로우 그래프를 따라 연산이 수행되는 형태인 flow를 합쳐 텐서플로(tensorflow)라고 부릅니다.</summary></entry><entry><title type="html">ROS2 첫걸음 (14) - 파라미터 사용(Python)</title><link href="https://refstop.github.io/ros2-custom_param.html" rel="alternate" type="text/html" title="ROS2 첫걸음 (14) - 파라미터 사용(Python)" /><published>2021-02-13T20:18:23+09:00</published><updated>2021-02-13T20:18:23+09:00</updated><id>https://refstop.github.io/ros2-custom_param</id><content type="html" xml:base="https://refstop.github.io/ros2-custom_param.html">&lt;h1 id=&quot;시작하며&quot;&gt;시작하며&lt;/h1&gt;
&lt;p&gt;이 게시글은 Python 노드에서 파라미터를 사용하는 방법을 정리합니다. 파라미터는 &lt;a href=&quot;https://refstop.github.io/posts/ros2-param/&quot;&gt;지난번&lt;/a&gt;에 turtlesim으로 한번 찍먹해본 적이 있습니다. 간단히 말하자면 노드 내에서 사용되는 변수이고, 이 값을 노드 내 또는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ros2 param&lt;/code&gt; 명령어를 통해 확인하거나 수정할 수 있습니다. 이번 게시글에서는 직접 생성, 수정을 해보도록 하겠습니다.&lt;/p&gt;

&lt;h1 id=&quot;1-parameter-전용-패키지-생성&quot;&gt;1. parameter 전용 패키지 생성&lt;/h1&gt;
&lt;p&gt;우선 파라미터 예제를 실습할 패키지를 생성합니다. 패키지의 위치는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/dev_ws/src&lt;/code&gt; 폴더 안입니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ros2 pkg create --build-type ament_python python_parameters --dependencies rclpy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--dependencies&lt;/code&gt; 명령어를 통해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rclpy&lt;/code&gt; 의존성 패키지를 추가합니다. 이렇게 추가한 의존성은 자동으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;package.xml&lt;/code&gt; 파일과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CMakeLists.txt&lt;/code&gt; 파일에 의존성 라인이 추가됩니다….만 파이썬 패키지는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CMakeLists.txt&lt;/code&gt; 파일이 없으므로 추가되지 않습니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;setup.py&lt;/code&gt; 파일에는 자동으로 추가되지 않으니 수정해 줘야 합니다. 우선 노드부터 작성 후 수정합시다.&lt;/p&gt;

&lt;h1 id=&quot;2-python-노드-작성&quot;&gt;2. Python 노드 작성&lt;/h1&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dev_ws/src/python_parameters/python_parameters&lt;/code&gt; 폴더에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;python_parameters_node.py&lt;/code&gt; 노드 소스 파일을 작성합니다. 내용은 다음과 같습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;import rclpy
import rclpy.node
from rclpy.exceptions import ParameterNotDeclaredException
from rcl_interfaces.msg import ParameterType

class MinimalParam(rclpy.node.Node):
    def __init__(self):
        super().__init__('minimal_param_node')
        timer_period = 2  # seconds
        self.timer = self.create_timer(timer_period, self.timer_callback)

        self.declare_parameter('my_parameter', 'world')

    def timer_callback(self):
        my_param = self.get_parameter('my_parameter').get_parameter_value().string_value

        self.get_logger().info('Hello %s!' % my_param)

        my_new_param = rclpy.parameter.Parameter(
            'my_parameter',
            rclpy.Parameter.Type.STRING,
            'world'
        )
        all_new_parameters = [my_new_param]
        self.set_parameters(all_new_parameters)

def main():
    rclpy.init()
    node = MinimalParam()
    rclpy.spin(node)

if __name__ == '__main__':
    main()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;코드를 분석해 봅시다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;import&lt;/code&gt; 명령어로 의존성 패키지를 추가합니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rclpy.exceptions&lt;/code&gt;는 파라미터를 사용하거나 수정하기 전에 선언이 안되있으면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ParameterNotDeclaredException&lt;/code&gt; 예외가 발생하게 하는 의존성입니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;import rclpy
import rclpy.node
from rclpy.exceptions import ParameterNotDeclaredException
from rcl_interfaces.msg import ParameterType
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;다음 부분은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MinimalParam&lt;/code&gt;의 생성자 함수입니다. 이 함수에서는 노드 이름, 타이머, 파라미터 선언을 합니다. 타이머는 시간 간격 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;timer_period&lt;/code&gt;와 타이머에 맞춰 실행될 함수 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;timer_callback&lt;/code&gt;을 타이머 함수에 대입합니다. 그리고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;declare_parameter&lt;/code&gt; 함수를 사용하여 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;my_parameter&lt;/code&gt;라는 이름의 파라미터에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;world&lt;/code&gt; 문자열을 저장하여 초기화합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;class MinimalParam(rclpy.node.Node):
    def __init__(self):
        super().__init__('minimal_param_node')
        timer_period = 2  # seconds
        self.timer = self.create_timer(timer_period, self.timer_callback)

        self.declare_parameter('my_parameter', 'world')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;타이머에 따라 실행될 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;timer_callback&lt;/code&gt; 함수입니다. 이 함수는 현재 파라미터의 내용을 출력해주는 기능과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ros2 param set&lt;/code&gt; 명령어로 파라미터를 수정했을 때 다시 원래 내용으로 되돌리는 기능을 갖고 있습니다. 파라미터 노드 생성 클래스의 내용은 이 함수까지입니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;def timer_callback(self):
    my_param = self.get_parameter('my_parameter').get_parameter_value().string_value

    self.get_logger().info('Hello %s!' % my_param)
    # world로 되돌리는 구문
    my_new_param = rclpy.parameter.Parameter(
        'my_parameter',
        rclpy.Parameter.Type.STRING,
        'world'
    )
    all_new_parameters = [my_new_param]
    self.set_parameters(all_new_parameters)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;마지막으로 남은 부분은 main함수와 main함수의 실행부입니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;def main():
    rclpy.init()
    node = MinimalParam()
    rclpy.spin(node)

if __name__ == '__main__':
    main()
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;3-setuppy-파일-수정&quot;&gt;3. setup.py 파일 수정&lt;/h1&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;setup.py&lt;/code&gt; 파일을 수정합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;entry_points={
    'console_scripts': [
        'param_talker = python_parameters.python_parameters_node:main',
    ],
},
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;4-빌드-소스-실행&quot;&gt;4. 빌드, 소스, 실행&lt;/h1&gt;
&lt;p&gt;이 과정은 많이 했으니 설명은 생략하겠습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ colcon build --packages-select python_parameters
$ . install/setup.bash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;실행-결과&quot;&gt;실행 결과&lt;/h1&gt;
&lt;p&gt;위에서 작성한 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;param_talker&lt;/code&gt; 노드의 실행 결과입니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ros2 run python_parameters param_talker 
[INFO] [minimal_param_node]: Hello world!
[INFO] [minimal_param_node]: Hello world!
[INFO] [minimal_param_node]: Hello world!
[INFO] [minimal_param_node]: Hello world!
[INFO] [minimal_param_node]: Hello world!
[INFO] [minimal_param_node]: Hello world!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이제 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ros2 param set&lt;/code&gt; 명령어로 파라미터를 수정해 보겠습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ros2 param set /minimal_param_node my_parameter earth
Set parameter successful
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;param_talker&lt;/code&gt; 노드가 실행되고 있는 터미널의 결과는 다음과 같습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ros2 run python_parameters param_talker 
[INFO] [minimal_param_node]: Hello world!
[INFO] [minimal_param_node]: Hello world!
[INFO] [minimal_param_node]: Hello world!
[INFO] [minimal_param_node]: Hello world!
[INFO] [minimal_param_node]: Hello world!
[INFO] [minimal_param_node]: Hello world!
[INFO] [minimal_param_node]: Hello world!
[INFO] [minimal_param_node]: Hello earth!
[INFO] [minimal_param_node]: Hello world!
[INFO] [minimal_param_node]: Hello world!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;my_parameter&lt;/code&gt; 파라미터가 잠깐 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;earth&lt;/code&gt;로 바뀌었다가 다시 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;world&lt;/code&gt;로 돌아왔습니다. 물론 위 소스의 원래대로 되돌리는 부분을 지우면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;earth&lt;/code&gt; 상태가 고정됩니다.&lt;/p&gt;

&lt;h1 id=&quot;launch-파일을-사용한-파라미터-수정&quot;&gt;launch 파일을 사용한 파라미터 수정&lt;/h1&gt;
&lt;p&gt;그렇다면 소스는 그대로 두고 파라미터만 수정할 수는 없을까요? launch 파일을 작성하면 할 수 있습니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/dev_ws/src/python_parameters&lt;/code&gt; 폴더에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;launch&lt;/code&gt; 폴더를 생성하여 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;python_parameters_launch.py&lt;/code&gt; 파일을 작성합니다. 내용은 다음과 같습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;from launch import LaunchDescription
from launch_ros.actions import Node

def generate_launch_description():
    return LaunchDescription([
        Node(
            package='python_parameters',
            node_executable='param_talker',
            node_name='custom_parameter_node',
            output='screen',
            parameters=[
                {'my_parameter': 'earth'}
            ]
        )
    ])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;그 후 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;setup.py&lt;/code&gt; 파일에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;import&lt;/code&gt; 구문과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;data_files&lt;/code&gt; 안의 구문을 추가합니다. launch 파일을 실행하기 위해 필요한 구문입니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;import os
from glob import glob
# ...

setup(
  # ...
  data_files=[
      # ...
      (os.path.join('share', package_name), glob('launch/*_launch.py')),
    ]
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;일반적인 노드 선언에서 다음 부분이 추가되었습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;parameters=[
    {'my_parameter': 'earth'}
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;my_parameter&lt;/code&gt; 파라미터를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;earth&lt;/code&gt;로 set하는 기능입니다. 물론 원래대로 되돌리는 구문에 의해 되돌아오긴 하지만 이런 방식으로 launch 파일에서 파라미터를 사용할 수 있습니다. 다만, launch 파일을 실행하면 터미널 창에 출력값이 보이지 않으므로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ros2 param get&lt;/code&gt; 명령어로 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ros2 launch python_parameters python_parameters_launch.py 
[INFO] [launch]: All log files can be found below /home/bhbhchoi/.ros/log/2021-02-15-15-14-38-127277-bhbhchoi-900X3L-11707
[INFO] [launch]: Default logging verbosity is set to INFO
[INFO] [param_talker-1]: process started with pid [11720]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ros2 param get /custom_parameter_node my_parameter
String value is: earth
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;저는 결과가 잘 나오는지 확인하기 위해 원래대로 되돌리는 구문은 주석처리하고 빌드, 소스 한 후 실행했습니다. 계속해서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;earth&lt;/code&gt;로 잘 나오고 있음을 볼 수 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;마무리&quot;&gt;마무리&lt;/h1&gt;
&lt;p&gt;ROS2 첫걸음 정리 게시글은 이것으로 마무리 하겠습니다. 아래 페이지를 번역만 해 놓은 것 같은 느낌이 들지만 ROS2를 맛볼 수 있었던 좋은 기회가 되었습니다.&lt;/p&gt;

&lt;h1 id=&quot;참고-사이트&quot;&gt;참고 사이트&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://index.ros.org/doc/ros2/Tutorials/Using-Parameters-In-A-Class-Python/&quot;&gt;ROS Index-ROS2 튜토리얼 파라미터 사용(Python)&lt;/a&gt;&lt;/p&gt;</content><author><name>Refstop</name></author><category term="ROS2" /><summary type="html">시작하며 이 게시글은 Python 노드에서 파라미터를 사용하는 방법을 정리합니다. 파라미터는 지난번에 turtlesim으로 한번 찍먹해본 적이 있습니다. 간단히 말하자면 노드 내에서 사용되는 변수이고, 이 값을 노드 내 또는 ros2 param 명령어를 통해 확인하거나 수정할 수 있습니다. 이번 게시글에서는 직접 생성, 수정을 해보도록 하겠습니다.</summary></entry><entry><title type="html">[Udacity] Deep Learning (3) - Nerual Network 비선형 모델</title><link href="https://refstop.github.io/uda-dl-nnnl.html" rel="alternate" type="text/html" title="[Udacity] Deep Learning (3) - Nerual Network 비선형 모델" /><published>2021-02-08T16:24:39+09:00</published><updated>2021-02-08T16:24:39+09:00</updated><id>https://refstop.github.io/uda-dl-nnnl</id><content type="html" xml:base="https://refstop.github.io/uda-dl-nnnl.html">&lt;h1 id=&quot;지난-게시글의-복습&quot;&gt;지난 게시글의 복습&lt;/h1&gt;
&lt;p&gt;지난 게시글들에서는 뉴럴 네트워크를 활성화 함수에 따라 이산 모델, 연속 모델로 나누어서 살펴보았습니다. 뉴럴 네트워크의 최종 목적은 정확한 예측 모델, 선형 함수를 만드는 것입니다. 이 선형 함수를 이산 모델에서는 Step Function, 연속 모델에서는 Sigmoid 또는 Softmax 함수에 대입합니다. 그 후 이산 모델에서는 퍼셉트론 알고리즘으로 가중치를 조절, 연속 모델에서는 Cross-Entropy 오차함수와 경사하강법을 사용하여 가중치를 조절합니다. 그 결과, 뉴럴 네트워크의 예측 모델인 선형 함수를 도출할 수 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;비선형-모델---다층-신경망&quot;&gt;비선형 모델 - 다층 신경망&lt;/h1&gt;
&lt;p&gt;이번 게시글에서는 비선형 모델에 대해서 알아보겠습니다. 비선형 모델은 어떤 식으로 찾을 수 있을까요? 바로 선형 함수를 여러개 합치는 것입니다. 간단한 예시를 보겠습니다.&lt;br /&gt;
&lt;img src=&quot;/assets/img/deeplearning/nonlinearex1.png&quot; alt=&quot;nonlinearex1&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;br /&gt;
위의 그림은 두 선형 함수를 합쳐서 비선형 함수를 만들어내는 과정입니다. 이 과정을 노드 그래프로 나타내면 다음과 같습니다.&lt;br /&gt;
&lt;img src=&quot;/assets/img/deeplearning/nonlinearex2.png&quot; alt=&quot;nonlinearex2&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;br /&gt;
맨 좌측부터 입력층, 은닉층, 출력층으로 이루어져 있습니다. 이렇게 입력층과 출력층 외의 은닉층이 존재하는 뉴럴 네트워크를 &lt;strong&gt;다층 신경망&lt;/strong&gt;이라고 합니다. 사실 은닉층이라고 해도 하는 일은 똑같습니다. 입력층의 입력을 받아 선형모델의 결과를 활성화 함수에 대입하여 은닉층의 결과를 도출합니다. 다시 은닉층의 결과값을 출력층에 대입하여 나온 출력이 바로 비선형 모델의 결과물입니다. 물론 여기서 추측할 수 있는 점은 입력이 $x_1, x_2, \cdots , x_n$과 같이 많아지면 많아질수록 출력이 나오기까지, 즉 결과가 분류되기까지 은닉층이 많아질 것입니다. 그렇다면 점점 더 복잡한 비선형 함수를 학습할 수 있게 됩니다.&lt;/p&gt;

&lt;h1 id=&quot;순전파-feedforward&quot;&gt;순전파 (Feedforward)&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/deeplearning/feedforward.png&quot; alt=&quot;feedforward&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;br /&gt;
이때 비선형 모델의 결과를 내는 과정을 순전파라고 합니다. 순리를 거스르지 않고 입력층부터 은닉층을 거쳐 출력층에서 출력을 내보냅니다. 위의 비선형 모델 다층 신경망 그림에 나온 과정을 그대로 따라갑니다.&lt;/p&gt;

&lt;h1 id=&quot;역전파-backpropagation&quot;&gt;역전파 (Backpropagation)&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/deeplearning/backpropagation.png&quot; alt=&quot;backpropagation&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;br /&gt;
역전파는 순전파와 반대로 출력값으로부터 입력값 방향으로 계산하여 가중치 조정값을 찾는 과정을 의미합니다. 저번 게시글에서 봤던 경사 하강법과는 다르게 다층 신경망에서 오차함수의 미분을 구할 때 사용하는 방법입니다. 오차함수를 가중치로 미분한 값의 의미는 &lt;strong&gt;이 가중치가 오차에 얼마나 영향을 미치는가&lt;/strong&gt;입니다. 저번과 마찬가지로 수정할 가중치에 대해 연쇄법칙을 사용하여 그 가중치가 영향을 미치는 노드들을 출력 쪽에서부터 되짚어 가면서 오차의 미분을 구합니다. 위의 그림에 표시된 가중치는 $W^{(1)}&lt;em&gt;{11}$입니다. 이 가중치에 대한 오차의 미분값을 계산해 보겠습니다. 오차함수를 $E(W)$로 표현하면, 오차를 가중치 $W^{(1)}&lt;/em&gt;{11}$에 대하여 미분한 값은 $\large{\frac{\partial E}{\partial W^{(1)}_{11}}}$입니다. 이 미분값을 연쇄법칙을 사용하여 나타낸 값은 다음과 같습니다.&lt;/p&gt;
&lt;center&gt;$\large{
\frac{\partial E}{\partial W^{(1)}_{11}}=\frac{\partial E}{\partial \hat{y}}\frac{\partial \hat{y}}{\partial h}\frac{\partial h}{\partial h_1}\frac{\partial h_1}{\partial W^{(1)}_{11}}
}$&lt;/center&gt;
&lt;p&gt;연쇄법칙한 결과의 각 항은 경사 하강법 때 계산했던 방식과 같은 방법으로 구할 수 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;마무리&quot;&gt;마무리&lt;/h1&gt;
&lt;p&gt;이번 강의에서 배운 뉴럴 네트워크는 여기까지입니다. 다음에 정리할 내용은 Tensorflow의 사용에 대해 정리해 보겠습니다.&lt;/p&gt;

&lt;h1 id=&quot;참고-사이트&quot;&gt;참고 사이트&lt;/h1&gt;
&lt;p&gt;Udacity Self-driving car nanodegree - Neural Network(링크 공유 불가능)&lt;/p&gt;</content><author><name>Refstop</name></author><category term="Udacity" /><category term="Deep Learning" /><summary type="html">지난 게시글의 복습 지난 게시글들에서는 뉴럴 네트워크를 활성화 함수에 따라 이산 모델, 연속 모델로 나누어서 살펴보았습니다. 뉴럴 네트워크의 최종 목적은 정확한 예측 모델, 선형 함수를 만드는 것입니다. 이 선형 함수를 이산 모델에서는 Step Function, 연속 모델에서는 Sigmoid 또는 Softmax 함수에 대입합니다. 그 후 이산 모델에서는 퍼셉트론 알고리즘으로 가중치를 조절, 연속 모델에서는 Cross-Entropy 오차함수와 경사하강법을 사용하여 가중치를 조절합니다. 그 결과, 뉴럴 네트워크의 예측 모델인 선형 함수를 도출할 수 있습니다.</summary></entry><entry><title type="html">[Udacity] Deep Learning (2) - Nerual Network 연속 모델</title><link href="https://refstop.github.io/uda-dl-nncm.html" rel="alternate" type="text/html" title="[Udacity] Deep Learning (2) - Nerual Network 연속 모델" /><published>2021-02-06T13:35:23+09:00</published><updated>2021-02-06T13:35:23+09:00</updated><id>https://refstop.github.io/uda-dl-nncm</id><content type="html" xml:base="https://refstop.github.io/uda-dl-nncm.html">&lt;h1 id=&quot;이산-모델에서-연속-모델로&quot;&gt;이산 모델에서 연속 모델로&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://refstop.github.io/posts/uda-dl-nndm/&quot;&gt;저번 게시글&lt;/a&gt;에선 로지스틱 회귀의 이산 모델에 대해서 정리했습니다. 하지만 경사 하강법을 사용하기 위해서는 연속 모델을 사용해야 합니다. 이산 모델과 비교하여 연속 모델에서 추가된 과정은 다음과 같습니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Sigmoid 함수 (확률함수)&lt;/li&gt;
  &lt;li&gt;Maximum Likelihood Estimation (최대우도법)&lt;/li&gt;
  &lt;li&gt;Cross-Entropy&lt;/li&gt;
  &lt;li&gt;Gradient Descent (경사 하강법)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;경사 하강법을 사용하기 위해서는 Cross-Entropy가 연속이어야 하고, Cross-Entropy에서 사용되는 최대우도법을 위해서는 확률 개념이 도입되어야 합니다. 이에 따라 선형 모델에 대한 확률을 나타낸 것이 바로 Sigmoid 함수입니다.&lt;/p&gt;

&lt;h1 id=&quot;1-sigmoid-함수&quot;&gt;1. Sigmoid 함수&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/deeplearning/sigmoid.png&quot; alt=&quot;sigmoid&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;br /&gt;
저번 게시글에서도 언급했던 시그모이드 함수입니다. 활성화 함수로 사용된다는 점에서 Step Function과 같은 포지션의 함수입니다. 하지만 Step Function과는 다르게 $x=0$을 기준으로 0과 1로 딱딱 맞게 나눠지지는 않습니다. 하지만 $x$의 절댓값이 약 5인 지점까지는 시그모이드 함수의 출력이 0 또는 1이 되지 않습니다. 이러한 점에 주목해 &lt;strong&gt;시그모이드 함수를 확률함수이자 활성화 함수&lt;/strong&gt;로 사용합니다. 이 함수는 로지스틱 회귀에 활성화 함수로서 사용하기 때문에 로지스틱 함수라고도 불립니다.&lt;/p&gt;

&lt;h1 id=&quot;2-maximum-likelihood-estimation-최대우도법&quot;&gt;2. Maximum Likelihood Estimation (최대우도법)&lt;/h1&gt;
&lt;center&gt;$\large{
P(x|\theta)=\prod_{k=1}^{n}P(x_k|\theta)\;\;\;\;\;\;\;P(x|\theta):\;예측이\;맞을\;확률
}$&lt;/center&gt;
&lt;p&gt;그 다음 과정은 시그모이드 함수에서 구한 확률들에 최대우도법을 적용하여 가장 좋은 모델, 즉 가장 확률이 높은 모델을 선정합니다. 최대우도법은 &lt;strong&gt;각 데이터 샘플에서 예측이 실제와 같을 확률을 계산하여 모두 곱한 것&lt;/strong&gt;입니다. 계산된 확률을 더해주지 않고 곱해주는 것은 모든 데이터들의 추출이 &lt;strong&gt;독립적으로 동시에 일어나는 사건&lt;/strong&gt;이기 때문입니다. 따라서 최대우도법 계산 결과값이 가장 높은 것을 가장 정확한 예측으로 봅니다.&lt;/p&gt;
&lt;center&gt;$\large{
ln(P(x|\theta))=\sum_{k=1}^{n}ln(P(x_k|\theta))
}$&lt;/center&gt;
&lt;p&gt;하지만 이 경우 하나의 확률만 바뀌어도 결과값이 심하게 바뀌므로, 곱셈을 덧셈의 형태로 표현해 줄 수 있는 로그함수를 취합니다. 덧셈으로 바꾸면 값 하나가 바뀌어도 결과값에 큰 영향이 가지 않습니다. 이 결과는 Cross-Entropy 오차함수를 만드는데 사용됩니다.&lt;/p&gt;

&lt;h1 id=&quot;3-cross-entropy-오차함수&quot;&gt;3. Cross-Entropy 오차함수&lt;/h1&gt;
&lt;p&gt;Cross-Entropy는 오차함수로 출력값이 작을수록 모델이 정확하다는 의미를 나타냅니다. 지난 과정에서 log likelihood 함수에 1보다 작은 값인 확률을 대입하기 때문에 결과가 항상 음수입니다. 따라서 비교의 용이를 위해 (-)부호를 취해 양수로 만들어 줍니다.&lt;/p&gt;
&lt;center&gt;$\large{
MLE=\sum_{k=1}^{n}ln(p_i)\rightarrow-\sum_{k=1}^{n}ln(p_i)
}$&lt;/center&gt;
&lt;p&gt;그 다음 이진적으로, 예를 들어 선물이 있다/없다, 샘플이 제대로 분류 되었다/되지 않았다를 판단할 때는 한쪽의 확률을 $p_i$, 다른 쪽의 확률을 $1-p_i$로 둡니다. 그리고 확률이 $p_i$일 때를 $y_i$=1, $1-p_i$일때를 $y_i$=0으로 두면 다음과 같은 식을 세울 수 있습니다.&lt;/p&gt;
&lt;center&gt;$\large{
Cross-Entropy = -\sum_{k=1}^{n}\left\{\begin{matrix}
ln(p_i)\;\;\;\;\;\;if\;y_i=1\\ 
ln(1-p_i)\;\;\;\;if\;y_i=0
\end{matrix}\right.
}$&lt;/center&gt;
&lt;p&gt;이때 $y_i$는 실제값으로 볼 수 있는데, $p(x=1)$, $p(x=0)$의 확률로 볼 수 있습니다. 이처럼 확률이 0 또는 1만으로 결과가 나오는 확률변수를 베르누이 확률변수라고 합니다. 위의 공식을 한줄로 표현하면 다음과 같은 식으로 나타낼 수 있습니다.&lt;/p&gt;
&lt;center&gt;$\large{
\begin{align*}
Cross-Entropy(y_i, p_i) &amp;amp;= -\sum_{k=1}^{n}\left\{\begin{matrix}
ln(p_i)\;\;\;\;\;\;if\;y_i=1\\ 
ln(1-p_i)\;\;\;\;if\;y_i=0
\end{matrix}\right. \\
&amp;amp;=-\sum_{k=1}^{n}y_iln(p_i)+(1-y_i)ln(1-p_i)
\end{align*}
}$&lt;/center&gt;
&lt;p&gt;이 공식에서 Cross-Entropy의 이름이 왜 교차 엔트로피인지를 볼 수 있습니다. $y_i$와 $p_i$ 두 확률이 교차(Cross)하는 계산에 의해 Entropy, 즉 정보량이 정해진다고 하여 Cross-Entropy인 것입니다. 즉 두 확률을 기반으로 구한 정보량이 Cross-Entropy인 것입니다. 결과값을 관찰하면 값이 작을수록, 즉 관계성이 옅을수록 낮은 값이 나옵니다. 다음의 예시가 이해를 도와줄 것입니다.&lt;br /&gt;
&lt;img src=&quot;/assets/img/deeplearning/ce_ex.png&quot; alt=&quot;ce_ex&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;&lt;br /&gt;
위의 예시는 3개의 문 뒤에 선물이 있을 확률을 나타낸 것입니다. n번째 문 뒤에 선물이 있을 확률은 각각 $p_n$입니다. 그리고 실제값 $y_i$는 선물이 있을 때 1, 없을 때 0을 의미합니다. 이때 일어날 확률이 가장 높은 값, 즉 예측값은 (0.8 0.7 0.9)이고 이때의 실제값은 (1 1 0)입니다. 따라서 이 확률과 실제값을 Cross-Entropy 오차함수에 대입하면 위의 그림에서 볼 수 있듯 0.69가 나옵니다. 반대로 가장 일어날 확률이 낮은 값, 즉 예측값에서 가장 먼 값을 Cross-Entropy 오차함수에 대입하면 5.12가 나옵니다. 예측값에서 작은 값을 출력되고, 예측값에서 먼 값일수록 큰 값을 출력하는 특징을 이용하여 Cross-Entropy를 오차함수로 사용합니다.&lt;/p&gt;

&lt;h1 id=&quot;4-gradient-descent&quot;&gt;4. Gradient Descent&lt;/h1&gt;
&lt;p&gt;오차가 큰지 작은지를 구했다면 구한 오차를 기반으로 가중치와 바이어스를 보정합니다. 여기서 경사 하강법을 사용하는데, 이는 적절한 가중치와 바이어스를 찾는 방법입니다. 높은 산에서 경사를 따라 내려오듯이 오차의 미분값을 따라 가중치를 조정합니다. 이산 모델에서의 퍼셉트론 알고리즘과 비슷한 포지션에 있습니다. 다음 이미지는 평균 제곱 오차(이하 MSE)의 경사하강법을 나타낸 그림입니다. 가로축은 가중치 $W$, 세로축은 오차 $Error$입니다.
&lt;img src=&quot;/assets/img/deeplearning/msegd.gif&quot; alt=&quot;msegd&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;&lt;/p&gt;
&lt;center&gt;$\large{
E(W)=\frac{1}{2m}\sum_{k=1}^{m}(y_i-\sigma(Wx+b))^2
}$&lt;/center&gt;
&lt;p&gt;MSE 함수는 오차함수로서 가중치와 오차의 관계를 2차 방정식으로 표현할 수 있습니다. 따라서 그림과 같은 형태의 그래프가 나오게 됩니다. 적절한 가중치를 찾기 위해서는 이 오차가 가중치에 끼치는 영향을 찾아 가중치에 더하거나 빼서 가중치를 보정해 줍니다. 그 과정은 다음과 같습니다.&lt;/p&gt;
&lt;center&gt;$\large{
\hat{y}=\sigma(Wx+b)
}$&lt;/center&gt;
&lt;center&gt;$\large{
\hat{y}=\sigma(w_1x_1+w_2x_2+\cdots+w_nx_n+b)
}$&lt;/center&gt;
&lt;p&gt;선형 모델을 활성화 함수에 넣은 모습입니다. 출력값은 확률입니다.&lt;/p&gt;
&lt;center&gt;$\large{
\triangledown E=(\frac{\partial E}{\partial w_1},\frac{\partial E}{\partial w_2},\cdots,\frac{\partial E}{\partial w_n})
}$&lt;/center&gt;
&lt;p&gt;이때 오차함수는 MSE, Cross-Entropy 등을 사용합니다.&lt;/p&gt;
&lt;center&gt;$\large{
\alpha=0.1\;\;(학습률)
}$&lt;/center&gt;
&lt;p&gt;오차함수의 미분값을 얼마나 반영할 것인지 정합니다. 학습률이 너무 작으면 오차 최솟값까지 가는데 시간이 너무 오래 걸릴 수 있고, 학습률이 너무 크면 가중치가 오차 최솟값이 되는 지점을 넘어가버려 오차 최솟값에 수렴하지 못할 수 있습니다.&lt;/p&gt;
&lt;center&gt;$\large{
w_i' \leftarrow w_i - \alpha\frac{\partial E}{\partial w_i}
}$&lt;/center&gt;
&lt;center&gt;$\large{
b_i' \leftarrow b_i-\alpha\frac{\partial E}{\partial b}
}$&lt;/center&gt;
&lt;p&gt;가중치와 바이어스에 오차함수의 미분에 비례한 값을 조정해 줍니다. 미분값이 작아질수록 가중치 변화가 작아지고, 0이 되면 최적 가중치가 됩니다. 모든 샘플에 대해 이 과정을 수행하기 때문에 이 새로운 가중치로 다시 경사 하강법을 수행합니다.&lt;/p&gt;
&lt;center&gt;$\large{
\hat{y}=\sigma(W'x+b')
}$&lt;/center&gt;

&lt;h2 id=&quot;cross-entropy의-w-error-그래프&quot;&gt;Cross-Entropy의 W-Error 그래프&lt;/h2&gt;
&lt;p&gt;사실 경사하강법에서 가장 문제가 되는 부분은 오차함수의 미분을 구하는 부분입니다. 그 이외에는 간단하기에 Cross-Entropy 오차함수의 미분을 구하는 방법을 알아보겠습니다. 먼저 시그모이드 함수의 미분을 구합니다.&lt;/p&gt;
&lt;center&gt;$\large{
z=Wx+b
}$&lt;/center&gt;
&lt;center&gt;$\large{
\hat{y}=\sigma(z)\;(Sigmoid)
}$&lt;/center&gt;
&lt;center&gt;$\large{
\frac{\partial \sigma}{\partial z}=\sigma(z)(1-\sigma(z))
}$&lt;/center&gt;
&lt;p&gt;시그모이드 함수의 미분은 간단하게 $\sigma(z)(1-\sigma(z))$로 표현할 수 있습니다. 다시 Cross-Entropy 오차함수를 참고하면 다음과 같습니다.&lt;/p&gt;
&lt;center&gt;$\large{
E(W)=-\sum_{k=1}^{n}y_iln(\sigma(z))+(1-y_i)ln(1-\sigma(z))
}$&lt;/center&gt;
&lt;p&gt;미분하기 두려워지게 생겼지만 괜찮습니다. 연쇄법칙을 적용하여 $\frac{\partial E}{\partial W}$를 풀어줍시다.&lt;/p&gt;
&lt;center&gt;$\large{
\begin{align*}
\frac{\partial E}{\partial W}&amp;amp;=\frac{\partial E}{\partial \sigma}\frac{\partial \sigma}{\partial z}\frac{\partial z}{\partial W}\;\;\;(연쇄법칙) \\
&amp;amp;=(\frac{1-y_i}{1-\sigma}-\frac{y_i}{\sigma})(\sigma(1-\sigma))X \\
&amp;amp;=(\sigma(z)-y_i)X \\
&amp;amp;=(\hat{y}-y_i)X
\end{align*}
}$&lt;/center&gt;
&lt;p&gt;미분하기 어렵게 생겼던 것 치고는 간단한 형태의 미분값이 나왔습니다. 이 값을 다음 식에 대입하여 새로운 가중치와 바이어스를 찾습니다.&lt;/p&gt;
&lt;center&gt;$\large{
w_i'\leftarrow w_i-\alpha \frac{\partial E}{\partial W}
}$&lt;/center&gt;
&lt;center&gt;$\large{
w_i'\leftarrow w_i+\alpha (y_i-\hat{y})x_i
}$&lt;/center&gt;
&lt;center&gt;$\large{
b_i'\leftarrow b_i-\alpha \frac{\partial E}{\partial b}
}$&lt;/center&gt;
&lt;center&gt;$\large{
b_i'\leftarrow b_i+\alpha (y_i-\hat{y})
}$&lt;/center&gt;
&lt;p&gt;생각보다 간결한 결과가 나왔습니다. 경사하강법은 이 과정을 모든 샘플에 대해 반복하여 가중치와 바이어스를 조정합니다. MSE의 그래프는 Cross-Entropy의 W-Error 그래프에 비해 직관적이기에 이해하기 쉽지만, 실제 Cross-Entropy 오차함수는 무시무시하게 생긴 경우가 많습니다. 실제 Cross-Entropy의 함수는 아니지만, 다음 그림처럼 아주 복잡한 함수를 예시로 들어 봅시다.
&lt;img src=&quot;/assets/img/deeplearning/ce_graph_ex.png&quot; alt=&quot;ce_graph_ex&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;&lt;br /&gt;
경사 하강법을 사용하는 데는 두 가지 문제가 있습니다.&lt;br /&gt;
첫번째는 그림에서 볼 수 있는 전역 최소값과 지역 최소값이 존재한다는 점입니다. 우리의 목표는 당연히 오차가 가장 낮아지는 전역 최솟값을 찾는 것입니다. 하지만 경사 하강법에는 지역 최소값에 대한 면역요소가 없기에, 지역 최소값에 속아넘어갈 수 있습니다. 이 문제를 해결하기 위해 고안된 것이 &lt;strong&gt;모멘텀(Momentum)&lt;/strong&gt;이란 방법입니다. 기존에 업데이트했던 미분값의 일정 비율을 남겨서 현재의 미분값에 더하여 가중치를 업데이트 하는 방식입니다.&lt;br /&gt;
두번째 문제는 모든 데이터를 계산하기에 수고가 많이 든다는 점입니다. 퍼셉트론 알고리즘과 다르게 맞는 샘플도, 틀린 샘플도 모두 검사하기에 계산량이 매우 많습니다. 이 문제를 해결하는 방법은 무작위로 샘플을 뽑아서 가중치 업데이트를 수행하는 &lt;strong&gt;확률적 경사 하강법(Stochastic Gradient Descent, SGD)&lt;/strong&gt;입니다. 완전히 정확한 결과를 얻는 것은 아니지만, 무작위 추출된 샘플이란 점에서 평균에 가까운 결과를 얻을 수 있고, 무엇보다 시간을 많이 단축시킬 수 있어 사용하는 방법입니다.&lt;/p&gt;

&lt;h2 id=&quot;perceptron-algorithm-vs-gradient-descent&quot;&gt;Perceptron Algorithm VS Gradient Descent&lt;/h2&gt;
&lt;p&gt;퍼셉트론 알고리즘과 경사 하강법의 차이는 바로 &lt;strong&gt;샘플의 검사 범위&lt;/strong&gt;입니다. 퍼셉트론 알고리즘은 잘못 분류된 샘플만 검사하고, 경사 하강법은 모든 샘플을 검사합니다. 따라서 모델은 경사 하강법이 더 정확하게 만들지만 수행하는데 걸리는 시간은 퍼셉트론 알고리즘이 더 짧습니다. 공학은 역시 Trade-off입니다.&lt;/p&gt;

&lt;h1 id=&quot;softmax와-one-hot-encoding&quot;&gt;Softmax와 One-Hot Encoding&lt;/h1&gt;
&lt;center&gt;$\large{
Softmax(z)=\frac{z_i}{\sum_{k=1}^{n}z_i}\;\;\;\rightarrow\;\;\;\frac{e^{z_i}}{\sum_{k=1}^{n}e^{z_i}}
}$&lt;/center&gt;
&lt;p&gt;소프트맥스는 시그모이드, step function과 같은 활성화 함수입니다. 3개 이상의 범주에 대한 확률을 나타낼때 사용합니다. 선형 모델의 각 결과값$(z_i)$을 모든 결과값의 합으로 나누어 표현합니다. 이는 결과값인 확률들의 총합을 1로 만들기 위함입니다. 하지만 이때 선형 모델의 결과값이 음수인 원소가 있을 때, 분모가 0이거나 0 이하로 내려가는 문제가 발생합니다. 소프트맥스는 활성화 함수로서 출력이 확률, 즉 양수로 나와야 하기 때문에 이 문제를 해결하기 위해 exp 함수를 사용합니다. exp 함수를 사용하면 선형 모델의 결과값의 합이 음수로 나오거나 분모가 0이 되는 경우를 막을 수 있습니다. 다음 그림으로 예시를 들겠습니다.
&lt;img src=&quot;/assets/img/deeplearning/softmax_ex.png&quot; alt=&quot;softmax_ex&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;&lt;br /&gt;
선형 모델의 결과가 (2.0 1.0 0.1)일 때, 결과값은 (0.7 0.2 0.1)이 나옵니다. 실제 결과값은 (0.6590011388859679, 0.2424329707047139, 0.09856589040931818)이지만, 소수점 둘째 자리에서 반올림한 값으로 생각합시다. 선형 모델의 결과가 높을수록 높은 확률이 출력되고, Softmax 함수의 출력값을 합하면 1이 되는 특징을 갖고 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/deeplearning/onehotex.png&quot; alt=&quot;onehotex&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;&lt;br /&gt;
원 핫 인코딩은 정답만을 1로 만드는 데이터 전처리 방식입니다. 컴퓨터가 데이터를 학습하기 전에 데이터를 가공해주는 것입니다. 정답에 1을 부여하고 정답이 아닌 항에는 0을 부여합니다. 예를 들어 위의 표에서 [1, 0, 0] 벡터는 사과를 의미합니다. [0, 1, 0] 벡터는 치킨을 의미합니다. 이 방식으로 크로스 엔트로피에 들어갈 실제값 데이터를 만듭니다. 다음 그림을 통해 예시를 살펴보겠습니다.
&lt;img src=&quot;/assets/img/deeplearning/onehotex2.png&quot; alt=&quot;onehotex2&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;&lt;br /&gt;
Softmax 결과값과 실제값 데이터를 전처리한 One-Hot Encoding 값을 비교합니다. 이 차이를 가지고 오차함수로 사용합니다. 이 경우, 그냥 |One-Hot Encoding 값 - Softmax 결과값|을 하여 오차를 구할 수도 있습니다. 이 방법을 사용하여 평균을 구한 것이 위에 잠깐 나왔던 MSE(평균 제곱 오차) 함수입니다. 하지만 여기서는 Cross-Entropy를 사용합니다. 
&lt;img src=&quot;/assets/img/deeplearning/cesmohe_ex.png&quot; alt=&quot;cesmohe_ex&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;&lt;br /&gt;
Softmax 함수의 결과값인 $S(y)$와 One-Hot Encoding의 결과인 라벨 $L$을 Cross-Entropy 오차함수에 대입하여 오차를 구합니다. 그러고 나면 위에서 설명했듯 Cross-Entropy는 두 확률간의 관계를 나타내는 방식으로 오차를 산출합니다.&lt;/p&gt;

&lt;h1 id=&quot;마무리&quot;&gt;마무리&lt;/h1&gt;
&lt;p&gt;다음 게시글은 NN의 비선형 모델에 대해 정리하겠습니다. 너무 길어 3편으로 나누어서 정리했네요. 한 강의에 이걸 다 넣을줄이야… 아무튼 다음 게시글에서 NN을 마무리하겠습니다.&lt;/p&gt;

&lt;h1 id=&quot;질문&quot;&gt;질문&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;이산 모델에서 연속 모델로 변경하는 이유를 잘 모르겠습니다. 정리한 게 맞나요?&lt;/li&gt;
  &lt;li&gt;최대우도법에서 초기 확률을 부여하는 법?&lt;/li&gt;
  &lt;li&gt;MSE보다 Cross-Entropy를 사용하는 이유?&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;참고-사이트&quot;&gt;참고 사이트&lt;/h1&gt;
&lt;p&gt;Udacity Self-driving car nanodegree - Neural Network(링크 공유 불가능)&lt;br /&gt;
&lt;a href=&quot;https://ratsgo.github.io/machine%20learning/2017/04/02/logistic/&quot;&gt;ratsgo’s blog - 로지스틱 회귀&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://angeloyeo.github.io/2020/07/17/MLE.html&quot;&gt;공돌이의 수학정리노트 - 최대우도법(MLE)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://john-analyst.medium.com/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC-%EB%A0%88%EC%9D%B4%EB%B8%94-%EC%9D%B8%EC%BD%94%EB%94%A9%EA%B3%BC-%EC%9B%90%ED%95%AB-%EC%9D%B8%EC%BD%94%EB%94%A9-f0220df21df1&quot;&gt;John 블로그 - 데이터 전처리 : 레이블 인코딩과 원핫 인코딩&lt;/a&gt;&lt;/p&gt;</content><author><name>Refstop</name></author><category term="Udacity" /><category term="Deep Learning" /><summary type="html">이산 모델에서 연속 모델로 저번 게시글에선 로지스틱 회귀의 이산 모델에 대해서 정리했습니다. 하지만 경사 하강법을 사용하기 위해서는 연속 모델을 사용해야 합니다. 이산 모델과 비교하여 연속 모델에서 추가된 과정은 다음과 같습니다. Sigmoid 함수 (확률함수) Maximum Likelihood Estimation (최대우도법) Cross-Entropy Gradient Descent (경사 하강법)</summary></entry><entry><title type="html">[Udacity] Deep Learning (1) - Nerual Network 이산 모델</title><link href="https://refstop.github.io/uda-dl-nndm.html" rel="alternate" type="text/html" title="[Udacity] Deep Learning (1) - Nerual Network 이산 모델" /><published>2021-02-04T15:14:23+09:00</published><updated>2021-02-04T15:14:23+09:00</updated><id>https://refstop.github.io/uda-dl-nndm</id><content type="html" xml:base="https://refstop.github.io/uda-dl-nndm.html">&lt;h1 id=&quot;neural-network란&quot;&gt;Neural Network란?&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/deeplearning/neural network.gif&quot; alt=&quot;neural network&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;br /&gt;
뉴럴 네트워크는 우리말로 신경망이라는 의미입니다. 옛날 옛적 공학자들은 컴퓨터에 지능, 즉 학습능력을 부여할 방법을 고민했고, 결국 사람의 뇌 구조를 모방하는 방법을 고안했습니다. 우리 뇌 속의 뉴런 세포가 연결 및 신호를 주고받는 방식을 알고리즘으로 구현하여 신경망이라는 것을 만들었습니다.&lt;br /&gt;
위 그림을 보면 뉴런 세포의 가지돌기(Dendrite)로 전기 신호가 전달되어 핵(Nucleus)을 통해 축삭(Axon)으로 전기 신호가 나갑니다. 지금부터 이러한 뉴런의 구조를 어떻게 구현했는지 알아볼 것입니다.&lt;/p&gt;

&lt;h1 id=&quot;선형-회귀-linear-regression&quot;&gt;선형 회귀 (Linear Regression)&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/deeplearning/linear regression.gif&quot; alt=&quot;linear regression&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;br /&gt;
먼저 가장 기초적인 선형 회귀를 살펴보겠습니다. 선형 회귀란 자료가 분포한 형태를 보고 $x$축과 $y$축 사이의 샘플 관계를 선형으로 나타내는 방법입니다. 일반적으로 선형 회귀 모델의 형태는 다음과 같습니다.&lt;/p&gt;
&lt;center&gt;$\large{
w_1x_1+w_2x_2+b=0
}$&lt;/center&gt;
&lt;p&gt;위의 공식에서는 가중치가 $w_1$, $w_2$ 둘 뿐이지만 실제로는 고려해야 할 가중치 수만큼 필요합니다. 데이터의 수가 $n$개라면, 그 수인 $n$개만큼 가중치가 존재합니다. 데이터와 가중치를 표현하면 다음과 같습니다.&lt;/p&gt;
&lt;center&gt;$\large{
X=\begin{bmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{bmatrix}
\;\;\;\;\;\;\;\;\;
W=\begin{bmatrix}
w_1 \\
w_2 \\
\vdots \\
w_n
\end{bmatrix}
}$&lt;/center&gt;
&lt;p&gt;바이어스는 그냥 $b$로 선형 모델당 하나입니다. 이들을 행렬로 된 식으로 나타내면 다음과 같습니다.&lt;/p&gt;
&lt;center&gt;$\large{
WX+b=0
}$&lt;/center&gt;
&lt;p&gt;하지만 이 강의에서는 이해를 돕기 위해서 2개의 가중치만 사용할 것입니다. 위의 그림에서 볼 수 있듯이 가중치와 바이어스 수정을 통해 선형 회귀 모델을 찾게  됩니다.&lt;/p&gt;

&lt;h1 id=&quot;로지스틱-회귀-logistic-regression&quot;&gt;로지스틱 회귀 (Logistic Regression)&lt;/h1&gt;
&lt;p&gt;로지스틱 회귀는 회귀를 사용하여 데이터가 어떤 범주에 속할 확률을 0에서 1 사이의 값으로 예측하고, 그 확률에 따라 가능성이 더 높은 범주에 속하는 것으로 분류해주는 지도 학습 알고리즘입니다. 핵심은 분류입니다. 회귀라고 부르지만 정작 기능은 분류인 이상한 녀석입니다. 이 이름의 유래는 연속형 변수 대신 범주형 변수에 회귀시키려다 발생한 문제입니다.&lt;/p&gt;

&lt;h2 id=&quot;로지스틱-회귀를-사용하는-이유&quot;&gt;로지스틱 회귀를 사용하는 이유&lt;/h2&gt;
&lt;p&gt;첫번째 예시는 나이에 따른 혈압의 증가 데이터입니다. 그래프를 보면 선형 회귀가 잘 이루어진 것을 볼 수 있습니다.
&lt;img src=&quot;/assets/img/deeplearning/logistic_ex1.png&quot; alt=&quot;logistic_ex1&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;&lt;br /&gt;
두번째 예시는 나이에 따른 암 발생 여부 데이터입니다. 데이터 결과값이 yes or no, 즉 0과 1로 출력됩니다. 데이터의 경향을 잘 따르는 첫번째 그래프와는 달리 이번 그래프는 뭔가 이상합니다.
&lt;img src=&quot;/assets/img/deeplearning/logistic_ex2.png&quot; alt=&quot;logistic_ex2&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;&lt;br /&gt;
결과값이 0~1 사이의 값이 나와야 하는데 양의 무한대, 음의 무한대까지 올라가 버립니다. 이것이 범주형 변수에 선형회귀를 적용했을 때의 문제입니다.
이제 어떤 방식으로 이 문제를 해결할 수 있는지 봅시다.&lt;/p&gt;

&lt;h2 id=&quot;로지스틱-회귀의-개요&quot;&gt;로지스틱 회귀의 개요&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/deeplearning/logistic node.png&quot; alt=&quot;logistic node&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;&lt;br /&gt;
로지스틱 회귀가 선택한 해결방법은 바로 &lt;strong&gt;활성화 함수(Activation Function)&lt;/strong&gt;를 사용하는 것입니다. 활성화 함수는 선형 모델을 비선형 모델로 만들어 주는 역할을 하고 있습니다. 선형 모델만 다층으로 쌓을 경우, 결국 결과가 선형 모델이 되는 문제점이 있기에, 비선형 함수를 한번 거쳐주는 과정이 필요합니다. 로지스틱 회귀에서 주로 사용되는 활성화 함수는 Step, Sigmoid, Softmax 함수입니다. 이 함수들은 어떤 *모델에서 적용하는지에 따라, 그리고 분류할 범주의 갯수에 따라 사용 함수가 다릅니다. 모델에 따라서는 Step Function은 이산 모델에서 사용하고, Sigmoid와 Softmax는 연속 모델에서 사용합니다. 또한 범주에 따라서는 범주가 2개(일반적으로 0 또는 1, yes or no 같은것)일 때 Step Function과 Sigmoid, 3개 이상일때 Softmax를 사용합니다. 이 함수들에 대해서는 앞으로 더 자세히 알아보도록 하겠습니다.&lt;/p&gt;

&lt;h1 id=&quot;선형-경계면-linear-boundary&quot;&gt;선형 경계면 (Linear Boundary)&lt;/h1&gt;
&lt;p&gt;계속해서 로지스틱 회귀를 알아보겠습니다. 다음의 자료는 학생들의 시험 시행 횟수에 따른 평균 등급을 샘플로 나타낸 것입니다.&lt;br /&gt;
&lt;img src=&quot;/assets/img/deeplearning/linear_bound.png&quot; alt=&quot;linear boundary&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;br /&gt;
시험 횟수가 많을수록, 그리고 성적이 높을수록 Pass 범주로, 시험 횟수가 적을수록, 그리고 성적이 낮을수록 Fail 범주로에 분류됩니다. 음… 그런데 시험 횟수가 적고 등급이 높은 사람은 불합격은 횟수가 걸릴 수 있으니 불합이 될 수 있지만, 시험 횟수가 많은데 등급이 낮은 사람은 합격이라… 이 결과는 뭔가 이상하네요. 아무튼 분류의 예시를 드는데는 문제가 없으니 이 데이터를 예시로 들겠습니다. 이 그림을 관찰해 보면 $w_1x_1+w_2x_2+b=0$의 선형 모델로 Pass와 Fail을 구분할 수 있습니다. 따라서 데이터를 선형 모델에 대입했을 때 $w_1x_1+w_2x_2+b$의 값이 0 이상이면, 즉 0이거나 양수이면 Pass, 0 이하, 즉 음수이면 Fail로 분류할 수 있습니다. 이때 Pass를 1, Fail을 0이라는 값을 부여한다고 하면 출력값, 결과 $y$의 함수는 다음과 같습니다.&lt;/p&gt;
&lt;center&gt;$\large{
y=\left\{\begin{matrix}
0\;\;\;\;if\;w_1x_1+w_2x_2+b&amp;lt;0\\ 
1\;\;\;\;if\;w_1x_1+w_2x_2+b\geq 0
\end{matrix}\right.
}$&lt;/center&gt;
&lt;p&gt;이 $y$의 함수를 그래프로 나타낸 것이 바로 Step Function입니다. 간단히 말해서 양수일때 1, 음수일때 0의 결과를 도출하는 함수입니다. 이산 모델에선 이 함수를 활성화 함수로 사용하게 됩니다.&lt;/p&gt;

&lt;h1 id=&quot;perceptron-algorithm&quot;&gt;Perceptron Algorithm&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/deeplearning/perceptron.gif&quot; alt=&quot;perceptron&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;&lt;br /&gt;
퍼셉트론 알고리즘은 가중치와 바이어스를 조정해 주는 알고리즘입니다. 잘못 분류된 sample의 성분을 현재 선형 모델에 적용하여 가중치 $w_1, w_2$와 바이어스 $b$를 보정해 줍니다. 하지만 한번에 그 sample의 성분만큼 조정하면 가중치와 바이어스의 변화가 너무 급격하기 때문에 학습률 $\alpha$로 반영 비율을 조정합니다. 이 과정을 잘못 분류된 모든 샘플에 대하여 시행합니다.&lt;br /&gt;
이 알고리즘이 반복되는 동안 선형 모델은 잘못된 sample에 점점 더 가까이 접근합니다. 결국 과정이 끝나고 나면 위 그림의 마지막과 같이 잘못된 sample을 분류하게 됩니다.&lt;/p&gt;

&lt;h1 id=&quot;마무리&quot;&gt;마무리&lt;/h1&gt;
&lt;p&gt;이산 모델의 선형 모델 찾는 방법은 여기까지입니다. 선형 모델을 찾은 후, 활성화 함수에 대입하여 0 또는 1의 결과를 구합니다. 다음 게시글에서는 이산 모델에서 연속 모델로 변화했을 때 추가되는 과정들을 알아보겠습니다.&lt;/p&gt;

&lt;h1 id=&quot;질문&quot;&gt;질문&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;딥러닝 방식, 즉 다층 신경망을 사용하는 방법은 모두 이런 방식인가요?&lt;/li&gt;
  &lt;li&gt;*이산 모델, 연속 모델이라고 사용하는게 맞나요?&lt;/li&gt;
  &lt;li&gt;Positive면 (–)해주고 negative면 (+)해주는 이유가 뭔가요?&lt;/li&gt;
  &lt;li&gt;가중치에 sample값을 반영하여 가중치를 수정할 수 있는 이유? 가중치와 sample(x1 x2)의 관계?&lt;/li&gt;
  &lt;li&gt;가중치를 초기화해줄 수 있는 방법은 없나요?&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;참고-사이트&quot;&gt;참고 사이트&lt;/h1&gt;
&lt;p&gt;Udacity Self-driving car nanodegree - Neural Network(링크 공유 불가능)&lt;/p&gt;</content><author><name>Refstop</name></author><category term="Udacity" /><category term="Deep Learning" /><summary type="html">Neural Network란? 뉴럴 네트워크는 우리말로 신경망이라는 의미입니다. 옛날 옛적 공학자들은 컴퓨터에 지능, 즉 학습능력을 부여할 방법을 고민했고, 결국 사람의 뇌 구조를 모방하는 방법을 고안했습니다. 우리 뇌 속의 뉴런 세포가 연결 및 신호를 주고받는 방식을 알고리즘으로 구현하여 신경망이라는 것을 만들었습니다. 위 그림을 보면 뉴런 세포의 가지돌기(Dendrite)로 전기 신호가 전달되어 핵(Nucleus)을 통해 축삭(Axon)으로 전기 신호가 나갑니다. 지금부터 이러한 뉴런의 구조를 어떻게 구현했는지 알아볼 것입니다.</summary></entry><entry><title type="html">[Udacity] Computer Vision (4) - Advanced CV</title><link href="https://refstop.github.io/uda-cv-adcv.html" rel="alternate" type="text/html" title="[Udacity] Computer Vision (4) - Advanced CV" /><published>2021-02-04T14:44:23+09:00</published><updated>2021-02-04T14:44:23+09:00</updated><id>https://refstop.github.io/uda-cv-adcv</id><content type="html" xml:base="https://refstop.github.io/uda-cv-adcv.html">&lt;h1 id=&quot;곡선-차선-검출&quot;&gt;곡선 차선 검출&lt;/h1&gt;
&lt;p&gt;지금까지 우리는 단지 차선을 검출한 방법에 대해서 공부했습니다. 하지만 직선이 아닌 곡선 차선일 경우 어떻게 자동차의 방향을 조절할 수 있을까요? 이번 게시글에서는 그 방법에 대해서 정리합니다. 대략적인 과정은 다음과 같습니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;히스토그램 구하기&lt;/li&gt;
  &lt;li&gt;슬라이드 윈도우 생성 (시각화)&lt;/li&gt;
  &lt;li&gt;곡률 반경 구하기&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;방향 조절을 위해서 곡률 반경을 구해야 합니다. 모터 제어값같은 하드웨어적 출력을 주는 코드는 컴퓨터 비전과는 관계가 없으므로, 결론적으로 곡률 반경을 구하는 것이 목적입니다.&lt;br /&gt;
&lt;img src=&quot;/assets/img/vision/warped_example.png&quot; alt=&quot;warped_example&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;br /&gt;
이번 강의에서는 위의 이미지를 예시로 사용합니다. 이 이미지는 저번 강의에서 사용했던 조감도(bird’s eye view)와 Gradient 검출 알고리즘으로 차선만을 흰색으로 검출한 결과입니다. 이번 강의는 거의 대부분이 코드 분석을 중심으로 진행됩니다. 단계별로 알아보도록 합시다.&lt;/p&gt;

&lt;h1 id=&quot;1-히스토그램-구하기&quot;&gt;1. 히스토그램 구하기&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/vision/histogram.png&quot; alt=&quot;histogram&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;br /&gt;
히스토그램은 통계학에서 나오는 막대그래프를 말합니다. $x$축의 각 좌표별, 즉 표본별 자료값을 나타낸 그래프입니다. 우리는 차선만을 검출하기 위해 히스토그램을 사용합니다. 코드를 통해 살펴봅시다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;# 이미지의 하단부만 취함
bottom_half = img[height//2:,:]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;먼저 이미지의 하단부만을 취하는 구문입니다. 다음 과정은 이미지의 세로 픽셀값을 모두 합하여 1차원 배열로 나타내는 것입니다. 따라서 그 과정의 계산을 줄이기 위해, 그리고 차선 시작점을 찾아야 하기 때문에 하단부 반쪽만 남겨서 계산합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;# 이미지 하단부의 세로값을 모두 합침.
histogram = np.sum(bottom_half, axis=0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이미지 세로값을 모두 합쳐 1차원 배열로 나타내는 구문입니다. 이때 결과로 나오는 배열이 히스토그램의 $y$축 값입니다. 이 배열을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;plt.plot&lt;/code&gt; 함수를 사용하여 이미지 위에 출력하여 결과를 봅시다.&lt;/p&gt;
&lt;h2 id=&quot;히스토그램-구하기-예제&quot;&gt;히스토그램 구하기 예제&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;import numpy as np
import matplotlib.image as mpimg
import matplotlib.pyplot as plt

img = mpimg.imread('/home/이미지 경로/warped_example.png')

height = img.shape[0]
width  = img.shape[1]

def hist(img):
    # 이미지의 하단부만 취함
    bottom_half = img[height//2:,:]

    # 이미지 하단부의 세로값을 모두 합침.
    histogram = np.sum(bottom_half, axis=0)
    
    return bottom_half, histogram

bottom_half, histogram = hist(img)

# 히스토그램 시각화 - 값이 비약적으로 높은 부분이 차선(흰색값)
plt.imshow(bottom_half, extent=[0, width, 0, height/2])
plt.plot(histogram)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Input:&lt;br /&gt;
&lt;img src=&quot;/assets/img/vision/warped_example.png&quot; alt=&quot;warped_example&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Output:&lt;br /&gt;
&lt;img src=&quot;/assets/img/vision/histogramresult.png&quot; alt=&quot;histogramresult&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;&lt;br /&gt;
결과를 보면 이미지를 반토막내서 히스토그램을 구한 것을 볼 수 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;2-슬라이드-윈도우-생성&quot;&gt;2. 슬라이드 윈도우 생성&lt;/h1&gt;
&lt;p&gt;다음 과정은 슬라이드 윈도우를 생성하는 것입니다. 코드는 크게 2가지 함수로 나누어집니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;윈도우 내의 픽셀 좌표 찾기
    &lt;ol&gt;
      &lt;li&gt;히스토그램 추출 &amp;amp; 최댓값(차선 중심 좌표) 구하기&lt;/li&gt;
      &lt;li&gt;윈도우 파라미터 설정&lt;/li&gt;
      &lt;li&gt;윈도우 그리기 &amp;amp; 차선 픽셀 검출&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;차선을 의미하는 2차함수 곡선 구하기 &amp;amp; 시각화
    &lt;ol&gt;
      &lt;li&gt;ployfit 함수 사용: 계수 찾기&lt;/li&gt;
      &lt;li&gt;차선, 곡선 시각화&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;윈도우 내의 픽셀 좌표를 찾는 함수와 그 픽셀 및 곡선을 시각화하는 함수로 나눌 수 있습니다. 각각의 함수 내의 단계를 코드를 보면서 알아보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;윈도우-내의-픽셀-좌표-찾기&quot;&gt;윈도우 내의 픽셀 좌표 찾기&lt;/h2&gt;
&lt;p&gt;함수를 선언한 후 내용을 보겠습니다. 시각화 함수에서 사용할 것이므로 선언부를 적어두겠습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;def find_lane_pixels(binary_warped):
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;1-히스토그램-추출--최댓값차선-중심-좌표-구하기&quot;&gt;1. 히스토그램 추출 &amp;amp; 최댓값(차선 중심 좌표) 구하기&lt;/h3&gt;
&lt;p&gt;먼저 앞선 과정에서 알아봤던 히스토그램을 구합니다. 이제는 한줄로 축약해서 구할 수 있습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;그 후, 이미지의 좌측과 우측에서 각각 히스토그램 최댓값을 구합니다. 그 지점(leftx_base, rightx_base)을 첫번째 윈도우의 중심점으로 사용할 것입니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;# 좌측 차선/우측 차선을 나누기 위해 이미지의 중심점 설정.
midpoint = np.int(histogram.shape[0]//2)
# 히스토그램에서 최댓값 취하기=차선이 있는 곳
leftx_base = np.argmax(histogram[:midpoint])
rightx_base = np.argmax(histogram[midpoint:]) + midpoint
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;2-윈도우-파라미터-설정&quot;&gt;2. 윈도우 파라미터 설정&lt;/h3&gt;
&lt;p&gt;다음 과정으로 윈도우 파라미터들을 설정합니다. 파라미터는 윈도우 갯수, 윈도우 너비, 최소 픽셀 갯수 등의 처음 설정값입니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;# HYPERPARAMETERS
# 윈도우 갯수
nwindows = 9
# 중심을 기준으로 좌우 윈도우 너비(100*2(양옆))
margin = 100
# 다음 중심을 정하기 위해 필요한 최소 픽셀 갯수
minpix = 50

# 윈도우의 높이 설정 - 이미지 세로/윈도우 갯수
window_height = np.int(binary_warped.shape[0]//nwindows)
# 이미지에서 0(검정색)이 아닌 픽셀 좌표
nonzero = binary_warped.nonzero()
nonzeroy = np.array(nonzero[0])
nonzerox = np.array(nonzero[1])
# 윈도우가 생겨날 중심, 계속 업데이트 됨
leftx_current = leftx_base
rightx_current = rightx_base

# 차선 픽셀들이 저장될 리스트
left_lane_inds = []
right_lane_inds = []
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;3-윈도우-그리기--차선-검출&quot;&gt;3. 윈도우 그리기 &amp;amp; 차선 검출&lt;/h3&gt;
&lt;p&gt;윈도우 갯수는 위의 파라미터에서 설정한 것과 같이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nwindows&lt;/code&gt;개 입니다. 따라서 반복문을 사용하여 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nwindows&lt;/code&gt;번 반복합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;# 윈도우 하나씩 만들어 보자.
for window in range(nwindows):
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;먼저 윈도우 사각형의 범위를 지정하고 그립니다. OpenCV에 내장된 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rectangle&lt;/code&gt; 함수를 사용합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;# window번째 윈도우의 범위 지정
# 세로 범위
win_y_low = binary_warped.shape[0] - (window+1)*window_height
win_y_high = binary_warped.shape[0] - window*window_height
# 왼쪽 가로 범위
win_xleft_low = leftx_current - margin
win_xleft_high = leftx_current + margin
# 오른쪽 가로 범위
win_xright_low = rightx_current - margin
win_xright_high = rightx_current + margin
      
# 윈도우 사각형 그리기
cv2.rectangle(out_img, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high), (0,255,0), 2)
cv2.rectangle(out_img, (win_xright_low, win_y_low), (win_xright_high, win_y_high), (0,255,0), 2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;그 다음, 윈도우 범위 내의 차선으로 예상되는 픽셀들을 구하여 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;leftx_lane_inds&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rightx_lane_inds&lt;/code&gt; 리스트에 저장합니다. 취한 픽셀 갯수가 설정해준 최솟값 이상일 때, 다음 윈도우의 중심을 픽셀들의 $x$좌표의 평균으로 저장합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;# 윈도우 범위 안에 있는 (차선으로 예상되는) nonzero 픽셀 취하기(1차원 배열)
# good_left_inds: (차선으로 예상되는) nonzero 픽셀 위치 리스트
good_left_inds = ((nonzeroy &amp;gt;= win_y_low) &amp;amp; (nonzeroy &amp;lt; win_y_high) &amp;amp; 
(nonzerox &amp;gt;= win_xleft_low) &amp;amp;  (nonzerox &amp;lt; win_xleft_high)).nonzero()[0]
good_right_inds = ((nonzeroy &amp;gt;= win_y_low) &amp;amp; (nonzeroy &amp;lt; win_y_high) &amp;amp; 
(nonzerox &amp;gt;= win_xright_low) &amp;amp;  (nonzerox &amp;lt; win_xright_high)).nonzero()[0]
       
# 취한 nonzero array(픽셀 리스트) 저장 (array, array, ...) 형태로 저장(술에 취한 아님)
# left_lane_inds: 각 층의 윈도우 안의 차선으로 예상되는 픽셀 리스트
left_lane_inds.append(good_left_inds)
right_lane_inds.append(good_right_inds)
       
# 취한 nonzero 픽셀 갯수가 minpix 이상일 때, 다음 차선의 중심(윈도우가 생겨날 곳)을 픽셀들의 x좌표의 평균으로 취함.
if len(good_left_inds) &amp;gt; minpix:
    leftx_current = np.int(np.mean(nonzerox[good_left_inds]))
if len(good_right_inds) &amp;gt; minpix:        
    rightx_current = np.int(np.mean(nonzerox[good_right_inds]))
# 배열1[배열2]: 배열2의 내용의 위치의 배열1 원소를 반환(numpy array만 가능)
# ex) a=[1,2,3,4,5] b=[2,3] -&amp;gt; a[b]=[3,4]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;그리고 어차피 이 좌표들은 차원이 상관 없기에 그냥 다 합쳐서 1차원 배열로 만듭니다. 그리고 좌우 차선을 의미하는 윈도우 안의 픽셀들과 이미지를 반환합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;# 그냥 1차원 배열로 퉁침
try:
    left_lane_inds = np.concatenate(left_lane_inds)
    right_lane_inds = np.concatenate(right_lane_inds)
except ValueError:
    # Avoids an error if the above is not implemented fully
    pass

# 좌우 윈도우 안의 픽셀 좌표들
leftx = nonzerox[left_lane_inds]
lefty = nonzeroy[left_lane_inds] 
rightx = nonzerox[right_lane_inds]
righty = nonzeroy[right_lane_inds]

return leftx, lefty, rightx, righty, out_img
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이로써 사실상 윈도우 안의 차선 검출은 끝났습니다. 하지만 진짜로 되었는지 확인하기 위해서 시각화 함수를 만들어 보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;차선을-의미하는-2차함수-곡선-구하기--시각화&quot;&gt;차선을 의미하는 2차함수 곡선 구하기 &amp;amp; 시각화&lt;/h2&gt;
&lt;p&gt;함수 선언부는 다음과 같습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;def fit_polynomial(binary_warped):
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;1-ployfit-함수-사용-계수-찾기&quot;&gt;1. ployfit 함수 사용: 계수 찾기&lt;/h3&gt;
&lt;p&gt;이번 과정에서는 차선 픽셀을 보고 ployfit 함수로 2차함수의 계수를 찾습니다. 그리고 그 계수로 그래프를 그릴 수 있도록 방정식을 선언합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;# 차선 픽셀 먼저 찾고
leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)

# 차선을 2차함수로 보고 계수 구하기
left_fit = np.polyfit(lefty, leftx, 2)
right_fit = np.polyfit(righty, rightx, 2)

# 그래프를 그리기 위한 방정식
ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )
try:
    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]
    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]
except TypeError:
    # Avoids an error if `left` and `right_fit` are still none or incorrect
    print('The function failed to fit a line!')
    left_fitx = 1*ploty**2 + 1*ploty
    right_fitx = 1*ploty**2 + 1*ploty
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;2-차선-곡선-시각화&quot;&gt;2. 차선, 곡선 시각화&lt;/h3&gt;
&lt;p&gt;차선과 곡선을 시각화 하기 위해 색상을 입힙니다. 이때 위에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dstack&lt;/code&gt; 함수로 3채널로 만들어 주었던 보람이 생깁니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;## 시각화 ##
# 좌/우 차선 색상 입히기
out_img[lefty, leftx] = [255, 0, 0]
out_img[righty, rightx] = [0, 0, 255]

# 좌/우 차선의 그래프 그리기(노란색)
plt.plot(left_fitx, ploty, color='yellow')
plt.plot(right_fitx, ploty, color='yellow')

return out_img
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;좌측 차선에 빨간색을, 우측 차선에 파란색을 입혔습니다. 2차 함수에는 노란색을 주어 잘 보이도록 했습니다.&lt;/p&gt;

&lt;p&gt;이 함수들을 실행하여 적절한 출력을 내는 코드를 작성하면, 다음과 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;슬라이드-윈도우-예제&quot;&gt;슬라이드 윈도우 예제&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;import numpy as np
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import cv2

img = mpimg.imread('/home/이미지 경로/warped_example.png')
# 채널 1로 줄이기 - 원본 코드에서는 이 과정이 없었으나 채널 문제로 인한 오류로 구문을 추가하였음.
# 원본 이미지는 채널이 4여서 채널 3을 요구하는 함수에서 오류가 발생했음.
binary_warped = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

def find_lane_pixels(binary_warped):
    # 히스토그램 추출
    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)
    # 시각화를 위한 채널 나누기, 각각 RGB 채널로 활용될 예정.
    out_img = np.dstack((binary_warped, binary_warped, binary_warped))
    # 좌측 차선/우측 차선을 나누기 위해 이미지의 중심점 설정.
    midpoint = np.int(histogram.shape[0]//2)
    # 히스토그램에서 최댓값 취하기=차선이 있는 곳
    leftx_base = np.argmax(histogram[:midpoint])
    rightx_base = np.argmax(histogram[midpoint:]) + midpoint

    # HYPERPARAMETERS
    # 윈도우 갯수
    nwindows = 9
    # 중심을 기준으로 좌우 윈도우 너비(100*2(양옆))
    margin = 100
    # 다음 중심을 정하기 위해 필요한 최소 픽셀 갯수
    minpix = 50

    # 윈도우의 높이 설정 - 이미지 세로/윈도우 갯수
    window_height = np.int(binary_warped.shape[0]//nwindows)
    # 이미지에서 0(검정색)이 아닌 픽셀 좌표
    nonzero = binary_warped.nonzero()
    nonzeroy = np.array(nonzero[0])
    nonzerox = np.array(nonzero[1])
    # 윈도우가 생겨날 곳, 계속 업데이트 됨
    leftx_current = leftx_base
    rightx_current = rightx_base

    # 차선 픽셀들이 저장될 리스트
    left_lane_inds = []
    right_lane_inds = []

    # 윈도우 하나씩 만들어 보자.
    for window in range(nwindows):
        # window번째 윈도우의 범위 지정
        # 세로 범위
        win_y_low = binary_warped.shape[0] - (window+1)*window_height
        win_y_high = binary_warped.shape[0] - window*window_height
        # 왼쪽 가로 범위
        win_xleft_low = leftx_current - margin
        win_xleft_high = leftx_current + margin
        # 오른쪽 가로 범위
        win_xright_low = rightx_current - margin
        win_xright_high = rightx_current + margin
        
        # 윈도우 사각형 그리기
        cv2.rectangle(out_img, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high), (0,255,0), 2)
        cv2.rectangle(out_img, (win_xright_low, win_y_low), (win_xright_high, win_y_high), (0,255,0), 2)
        
        # 윈도우 범위 안에 있는 (차선으로 예상되는) nonzero 픽셀 취하기(1차원 배열)
        # good_left_inds: (차선으로 예상되는) nonzero 픽셀 위치 리스트
        good_left_inds = ((nonzeroy &amp;gt;= win_y_low) &amp;amp; (nonzeroy &amp;lt; win_y_high) &amp;amp; 
        (nonzerox &amp;gt;= win_xleft_low) &amp;amp;  (nonzerox &amp;lt; win_xleft_high)).nonzero()[0]
        good_right_inds = ((nonzeroy &amp;gt;= win_y_low) &amp;amp; (nonzeroy &amp;lt; win_y_high) &amp;amp; 
        (nonzerox &amp;gt;= win_xright_low) &amp;amp;  (nonzerox &amp;lt; win_xright_high)).nonzero()[0]
        
        # 취한 nonzero array(픽셀 리스트) 저장 (array, array, ...) 형태로 저장(술에 취한 아님)
        # left_lane_inds: 각 층의 윈도우 안의 차선으로 예상되는 픽셀 리스트
        left_lane_inds.append(good_left_inds)
        right_lane_inds.append(good_right_inds)
        
        # 취한 nonzero 픽셀 갯수가 minpix 이상일 때, 다음 차선의 중심(윈도우가 생겨날 곳)을 픽셀들의 x좌표의 평균으로 취함.
        if len(good_left_inds) &amp;gt; minpix:
            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))
        if len(good_right_inds) &amp;gt; minpix:        
            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))
        # 배열1[배열2]: 배열2의 내용의 위치의 배열1 원소를 반환(numpy array만 가능)
        # ex) a=[1,2,3,4,5] b=[2,3] -&amp;gt; a[b]=[3,4]

    # 그냥 1차원 배열로 퉁침.
    try:
        left_lane_inds = np.concatenate(left_lane_inds)
        right_lane_inds = np.concatenate(right_lane_inds)
    except ValueError:
        # Avoids an error if the above is not implemented fully
        pass

    # 좌우 윈도우 안의 픽셀 좌표들
    leftx = nonzerox[left_lane_inds]
    lefty = nonzeroy[left_lane_inds] 
    rightx = nonzerox[right_lane_inds]
    righty = nonzeroy[right_lane_inds]

    return leftx, lefty, rightx, righty, out_img


def fit_polynomial(binary_warped):
    # 차선 픽셀 먼저 찾고
    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)

    # 차선을 2차함수로 보고 계수 구하기
    left_fit = np.polyfit(lefty, leftx, 2)
    right_fit = np.polyfit(righty, rightx, 2)

    # 그래프를 그리기 위한 방정식
    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )
    try:
        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]
        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]
    except TypeError:
        # Avoids an error if `left` and `right_fit` are still none or incorrect
        print('The function failed to fit a line!')
        left_fitx = 1*ploty**2 + 1*ploty
        right_fitx = 1*ploty**2 + 1*ploty

    ## 시각화 ##
    # 좌/우 차선 색상 입히기
    out_img[lefty, leftx] = [255, 0, 0]
    out_img[righty, rightx] = [0, 0, 255]

    # 좌/우 차선의 그래프 그리기(노란색)
    plt.plot(left_fitx, ploty, color='yellow')
    plt.plot(right_fitx, ploty, color='yellow')

    return out_img


out_img = fit_polynomial(binary_warped)

plt.imshow(out_img)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Input:&lt;br /&gt;
히스토그램 구하기 예제와 같습니다.&lt;/p&gt;

&lt;p&gt;Output:&lt;br /&gt;
&lt;img src=&quot;/assets/img/vision/slidewindowresult.png&quot; alt=&quot;slidewindowresult&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;이전-프레임으로부터-윈도우-중심-찾기&quot;&gt;이전 프레임으로부터 윈도우 중심 찾기&lt;/h2&gt;
&lt;p&gt;하지만 매 프레임마다 2차방정식 계수를 계산하는 것은 계산적으로 낭비가 많습니다. 따라서 이번에는 이전 프레임에서의 2차 방정식 계수를 기반으로 차선을 따라가는 윈도우를 작성합니다. 윈도우라기보단 한줄짜리 선을 이어붙인 도형입니다. 위의 슬라이드 윈도우 만들기와 과정은 비슷합니다. 코드를 통해 살펴도록 하겠습니다.&lt;br /&gt;
먼저 다항식 계수를 구하는 함수입니다. 이후 작성할 함수에서 사용될 예정입니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;def fit_poly(img_shape, leftx, lefty, rightx, righty):
    # 다항식 계수 구하기
    # 지역 변수로서 left_fit, right_fit. 전역 변수의 수정은 없다.
    left_fit = np.polyfit(lefty, leftx, 2)
    right_fit = np.polyfit(righty, rightx, 2)
    # 그래프 그리기 위해 방정식 &amp;amp; 범위 규정
    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])
    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]
    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]
    
    return left_fitx, right_fitx, ploty
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;다음 함수는 윈도우를 만드는 함수입니다. 선언부는 다음과 같습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;def search_around_poly(binary_warped):
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;저번 윈도우와 같이 탐색할 차선의 중심 기준 좌우 범위를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;margin&lt;/code&gt;으로 놓습니다. 그 후 차선이 포함된 흰색 픽셀을 검출합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;# HYPERPARAMETER
margin = 100

# 흰색 픽셀 검출(이미지 전체)
nonzero = binary_warped.nonzero()
nonzeroy = np.array(nonzero[0])
nonzerox = np.array(nonzero[1])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;그 후 한줄짜리 윈도우를 만듭니다. 사실 사각형이 아닌 선 하나이기 때문에 한줄짜리 윈도우라고 부릅니다. 슬라이드 윈도우에서 사용했던 윈도우 중심점 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;leftx_current, rightx_current&lt;/code&gt; 대신 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2], right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2]&lt;/code&gt;를 사용합니다. 2차 방정식의 값을 중심으로 양 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;margin&lt;/code&gt; 범위 내에서 흰색 픽셀을 찾아냅니다. 이 픽셀들을 차선으로 봅니다. 그 후 찾은 픽셀들의 $x$, $y$ 값을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;leftx, lefty, rightx, righty&lt;/code&gt; 변수에 저장합니다. 이 변수을 위에서 작성했던 다항식 계수를 구하는 함수에 대입하여 시각화를 위한 픽셀을 구합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;# 윈도우 중심점 대신 left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] 를 사용.
# 이전 프레임에서 사용했던 left, right_fit 사용, 한줄씩만 픽셀 검출
left_lane_inds = ((nonzerox &amp;gt; (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + 
                left_fit[2] - margin)) &amp;amp; (nonzerox &amp;lt; (left_fit[0]*(nonzeroy**2) + 
                left_fit[1]*nonzeroy + left_fit[2] + margin)))
right_lane_inds = ((nonzerox &amp;gt; (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + 
                right_fit[2] - margin)) &amp;amp; (nonzerox &amp;lt; (right_fit[0]*(nonzeroy**2) + 
                right_fit[1]*nonzeroy + right_fit[2] + margin)))
    
# 검출한 차선의 x, y값 저장
leftx = nonzerox[left_lane_inds]
lefty = nonzeroy[left_lane_inds] 
rightx = nonzerox[right_lane_inds]
righty = nonzeroy[right_lane_inds]

# 다항식 결과물, 범위
left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;다음은 시각화 단계입니다. 지금까지 구한 정보를 토대로 윈도우, 그래프를 시각화합니다. 이 과정은 위의 슬라이드 윈도우 시각화 과정과 크게 다르지 않습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;## 시각화 ##
# 컬러 시각화를 위한 채널 추가
out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255
window_img = np.zeros_like(out_img)
# 좌우 차선 픽셀에 색상값 추가
out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]
out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]

# cv2.fillpoly() 함수에서 사용할 한줄짜리 윈도우 픽셀 좌표
left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])
left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])
left_line_pts = np.hstack((left_line_window1, left_line_window2))
right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])
right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])
right_line_pts = np.hstack((right_line_window1, right_line_window2))

# 선을 따라가는 한줄짜리 윈도우 시각화
cv2.fillPoly(window_img, np.int_([left_line_pts]), (0, 255, 0))
cv2.fillPoly(window_img, np.int_([right_line_pts]), (0, 255, 0))
result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)
    
# 곡선 그래프 시각화
plt.plot(left_fitx, ploty, color = 'yellow')
plt.plot(right_fitx, ploty, color = 'yellow')
    
return result
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;이전-프레임으로부터-윈도우-중심-찾기-예제&quot;&gt;이전 프레임으로부터 윈도우 중심 찾기 예제&lt;/h3&gt;
&lt;p&gt;지금까지 설명한 예제의 전문을 보겠습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;import cv2
import numpy as np
import matplotlib.image as mpimg
import matplotlib.pyplot as plt

# Load our image - this should be a new frame since last time!
img = mpimg.imread('/home/이미지 경로/warped_example.png')
binary_warped = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
# 이전 프레임에서의 2차 방정식 계수, 실제 코드에선 이전 프레임 것을 사용해야 함.
left_fit = np.array([ 2.13935315e-04, -3.77507980e-01,  4.76902175e+02])
right_fit = np.array([4.17622148e-04, -4.93848953e-01,  1.11806170e+03])

def fit_poly(img_shape, leftx, lefty, rightx, righty):
    # 다항식 계수 구하기
    # 지역 변수로서 left_fit, right_fit. 전역 변수의 수정은 없다.
    left_fit = np.polyfit(lefty, leftx, 2)
    right_fit = np.polyfit(righty, rightx, 2)
    # 그래프 그리기 위해 방정식 &amp;amp; 범위 규정
    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])
    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]
    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]
    
    return left_fitx, right_fitx, ploty

def search_around_poly(binary_warped):
    # HYPERPARAMETER
    margin = 100

    # 흰색 픽셀 검출(이미지 전체)
    nonzero = binary_warped.nonzero()
    nonzeroy = np.array(nonzero[0])
    nonzerox = np.array(nonzero[1])
    print(nonzeroy)
    # 윈도우 중심점 대신 left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] 를 사용.
    # 이전 프레임에서 사용했던 left, right_fit 사용, 한줄씩만 픽셀 검출
    left_lane_inds = ((nonzerox &amp;gt; (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + 
                    left_fit[2] - margin)) &amp;amp; (nonzerox &amp;lt; (left_fit[0]*(nonzeroy**2) + 
                    left_fit[1]*nonzeroy + left_fit[2] + margin)))
    right_lane_inds = ((nonzerox &amp;gt; (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + 
                    right_fit[2] - margin)) &amp;amp; (nonzerox &amp;lt; (right_fit[0]*(nonzeroy**2) + 
                    right_fit[1]*nonzeroy + right_fit[2] + margin)))
    
    # 검출한 차선의 x, y값 저장
    leftx = nonzerox[left_lane_inds]
    lefty = nonzeroy[left_lane_inds] 
    rightx = nonzerox[right_lane_inds]
    righty = nonzeroy[right_lane_inds]

    # 다항식 결과물, 범위
    left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)

    ## 시각화 ##
    # 컬러 시각화를 위한 채널 추가
    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255
    window_img = np.zeros_like(out_img)
    # 좌우 차선 픽셀에 색상값 추가
    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]
    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]

    # cv2.fillpoly() 함수에서 사용할 한줄짜리 윈도우 픽셀 좌표
    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])
    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])
    left_line_pts = np.hstack((left_line_window1, left_line_window2))
    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])
    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])
    right_line_pts = np.hstack((right_line_window1, right_line_window2))

    # 선을 따라가는 한줄짜리 윈도우 시각화
    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0, 255, 0))
    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0, 255, 0))
    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)
    
    # 곡선 그래프 시각화
    plt.plot(left_fitx, ploty, color = 'yellow')
    plt.plot(right_fitx, ploty, color = 'yellow')
    
    return result

result = search_around_poly(binary_warped)

plt.imshow(result)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Input:&lt;br /&gt;
히스토그램 구하기 예제와 같습니다.&lt;/p&gt;

&lt;p&gt;Output:&lt;br /&gt;
&lt;img src=&quot;/assets/img/vision/preframeresult.png&quot; alt=&quot;preframeresult&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-곡률-반경-구하기&quot;&gt;3. 곡률 반경 구하기&lt;/h1&gt;
&lt;p&gt;곡선 차선을 검출하여 차량 방향을 조향하기 위한 마지막 단계입니다. 이 과정은 2차 방정식으로 곡률 반경을 찾는 과정입니다. 2차 방정식으로부터 곡률 반경을 찾는 공식은 다음과 같습니다.&lt;/p&gt;
&lt;center&gt;$\large{
R_{curve}=\frac{(1+(\frac{dy}{dx})^2)^\frac{3}{2}}{|\frac{d^2y}{dx^2}|}
}$&lt;/center&gt;
&lt;center&gt;$\large{
f(x)=y=Ax^2+Bx+C
}$&lt;/center&gt;
&lt;center&gt;$\large{
f'(x)=y'=2Ax+B
}$&lt;/center&gt;
&lt;center&gt;$\large{
f''(x)=y''=2A
}$&lt;/center&gt;
&lt;center&gt;$\large{
R_{curve}=\frac{(1+(2Ax+B)^2)^\frac{3}{2}}{|2A|}
}$&lt;/center&gt;
&lt;p&gt;이 공식을 참고하여 코드를 작성합니다.&lt;/p&gt;

&lt;h2 id=&quot;곡률-반경-구하기-예제&quot;&gt;곡률 반경 구하기 예제&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&quot;language-{.python}&quot;&gt;# 슬라이드 윈도우 단계에서 구한 ploty, left_fit, right_fit를 파라미터로 사용
def measure_curvature_pixels(ploty, left_fit, right_fit):
    # 곡률 반경을 볼 지점 선택, 이 예제에서는 이미지 제일 하단의 지점을 선택했습니다.
    y_eval = np.max(ploty)
    
    # 곡률 반경 공식
    left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])
    right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])
    
    return left_curverad, right_curverad
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;참고-사이트&quot;&gt;참고 사이트&lt;/h1&gt;
&lt;p&gt;Udacity Self-driving car nanodegree - Advanced CV(링크 공유 불가능)&lt;/p&gt;</content><author><name>Refstop</name></author><category term="Udacity" /><category term="Computer Vision" /><summary type="html">곡선 차선 검출 지금까지 우리는 단지 차선을 검출한 방법에 대해서 공부했습니다. 하지만 직선이 아닌 곡선 차선일 경우 어떻게 자동차의 방향을 조절할 수 있을까요? 이번 게시글에서는 그 방법에 대해서 정리합니다. 대략적인 과정은 다음과 같습니다. 히스토그램 구하기 슬라이드 윈도우 생성 (시각화) 곡률 반경 구하기</summary></entry></feed>